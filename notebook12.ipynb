{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca4a49d",
   "metadata": {},
   "source": [
    "# 12. Perzeptron\n",
    "\n",
    "Durch neuronale Netze, die tief verschachtelt sind (= tiefe neuronale Netze =\n",
    "deep neural network), gab es im Bereich des maschinellen Lernens einen\n",
    "Durchbruch. Neuronale Netze sind eine Technik aus der Statistik, die bereits in\n",
    "den 1940er Jahren entwickelt wurde. Seit ca. 10 Jahren erlebt diese Technik\n",
    "verbunden mit Fortschritten in der Computertechnologie eine Renaissance.\n",
    "\n",
    "Neuronale Netze bzw. Deep Learning kommen vor allem da zum Einsatz, wo es kaum\n",
    "systematisches Wissen gibt. Damit neuronale Netze erfolgreich trainiert werden\n",
    "können, brauchen sie sehr große Datenmengen. Nachdem in den letzten 15 Jahren\n",
    "mit dem Aufkommen von Smartphones die Daten im Bereich Videos und Fotos massiv\n",
    "zugenommen haben, lohnt sich der Einsatz der neuronalen Netze für\n",
    "Spracherkennung, Gesichtserkennung oder Texterkennung besonders.\n",
    "\n",
    "Beispielsweise hat ein junges deutsches Start-Up-Unternehmen 2017 aus einem\n",
    "neuronalen Netz zum Übersetzen Englisch <-> Deutsch eine Webanwendung entwickelt\n",
    "und ins Internet gestellt, die meinen Alltag massiv beeinflusst:\n",
    "\n",
    "> DeepL.com\n",
    "\n",
    "Auf der Seite\n",
    "\n",
    "> [https://www.deepl.com/en/blog/how-does-deepl-work](https://www.deepl.com/en/blog/how-does-deepl-work)\n",
    "\n",
    "finden Sie einen kurzen Übersichtsartikel dazu, wie DeepL funktioniert.\n",
    "\n",
    "Die Grundlage der neuronalen Netze ist das Perzeptron, mit dem wir uns in diesem\n",
    "Kapitel beschäftigen.\n",
    "\n",
    "## 12.1 Grundbaustein neuronaler Netze\n",
    "\n",
    "Neuronale Netze sind sehr beliebte maschinelle Lernverfahren. Das einfachste künstliche neuronale Netz ist das **Perzeptron**. In diesem Abschnitt werden wir das Perzeptron vorstellen.\n",
    "\n",
    "### Lernziele Kapitel 12.1\n",
    "\n",
    "* Sie können das Perzeptron als mathematische Funktion formulieren und in dem Zusammenhang die folgenden Begriffe erklären:\n",
    "  * gewichtete Summe (Weighted Sum),\n",
    "  * Bias oder Bias-Einheit (Bias),\n",
    "  * Schwellenwert (Threshold)  \n",
    "  * Heaviside-Funktion (Heaviside Function) und\n",
    "  * Aktivierungsfunktion (Activation Function).\n",
    "* Sie können das Perzeptron als ein binäres Klassifikationsproblem des überwachten Lernens einordnen.\n",
    "\n",
    "### Die Hirnzelle dient als Vorlage für künstliche Neuronen\n",
    "\n",
    "1943 haben die Forscher Warren McCulloch und Walter Pitts das erste Modell einer vereinfachten Hirnzelle präsentiert. Zu Ehren der beiden Forscher heißt dieses Modell MCP-Neuron. Darauf aufbauend publizierte Frank Rosenblatt 1957 seine Idee einer Lernregel für das künstliche Neuron. Das sogenannte Perzeptron bildet bis heute die Grundlage der künstlichen neuronalen Netze. Inspiriert wurden die Forscher dabei durch den Aufbau des Gehirns und der Verknüpfung der Nervenzellen.\n",
    "\n",
    "![Darstellung einer Nervenzelle](https://gramschs.github.io/book_ml4ing/_images/neuron_wikipedia.svg)\n",
    "\n",
    "([Quelle:](https://de.wikipedia.org/wiki/Künstliches_Neuron#/media/Datei:Neuron_(deutsch)-1.svg) \"Schematische Darstellung einer Nervenzelle\" von Autor unbekannt. Lizenz: [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0/))\n",
    "\n",
    "Elektrische und chemische Eingabesignale kommen bei den Dendriten an und laufen im Zellkörper zusammen. Sobald ein bestimmter Schwellwert überschritten wird, wird ein Ausgabesignal erzeugt und über das Axon weitergeleitet. Mehr Details zu Nervenzellen finden Sie bei [Wikipedia/Nervenzelle](https://de.wikipedia.org/wiki/Nervenzelle).\n",
    "\n",
    "### Eine mathematische Ungleichung ersetzt das logische Oder\n",
    "\n",
    "Das einfachste künstliche Neuron besteht aus zwei Inputs und einem Output. Dabei sind für die beiden Inputs nur zwei Zustände zugelassen und auch der Output besteht nur aus zwei verschiedenen Zuständen. In der Sprache des maschinellen Lernens liegt also eine **binäre Klassifikationsaufgabe** innerhalb des **Supervised Learnings** vor.\n",
    "\n",
    "Beispiel:\n",
    "\n",
    "* Input 1: Es regnet oder es regnet nicht.\n",
    "* Input 2: Der Rasensprenger ist an oder nicht.\n",
    "* Output: Der Rasen wird nass oder nicht.\n",
    "\n",
    "Den Zusammenhang zwischen Regen, Rasensprenger und nassem Rasen können wir in einer Tabelle abbilden:\n",
    "\n",
    "Regnet es? | Ist Sprenger an? | Wird Rasen nass?\n",
    "-----------|------------------|-----------------\n",
    "nein       | nein             | nein\n",
    "ja         | nein             | ja\n",
    "nein       | ja               | ja\n",
    "ja         | ja               | ja\n",
    "\n",
    "Wir schreiben ein kurzes Python-Programm, das abfragt, ob es regnet und ob der\n",
    "Rasensprenger eingeschaltet ist. Dann soll der Python-Interpreter ausgeben, ob\n",
    "der Rasen nass wird oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06278daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe\n",
    "x1 = input('Regnet es (j/n)?')\n",
    "x2 = input('Ist der Rasensprenger eingeschaltet? (j/n)')\n",
    "\n",
    "# Verarbeitung\n",
    "y = (x1 == 'j') or (x2 == 'j')\n",
    "\n",
    "# Ausgabe\n",
    "if y == True:\n",
    "    print('Der Rasen wird nass.')\n",
    "else:\n",
    "    print('Der Rasen wird nicht nass.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5fec7",
   "metadata": {},
   "source": [
    "Für das maschinelle Lernen müssen die Daten als Zahlen aufbereitet werde, damit\n",
    "die maschinellen Lernverfahren in der Lage sind, Muster in den Daten zu\n",
    "erlernen. Anstatt \"Regnet es? Nein.\" oder Variablen mit True/False setzen wir\n",
    "jetzt Zahlen ein. Die Inputklassen kürzen wir mit x1 für Regen und x2 für\n",
    "Rasensprenger ab. Die 1 steht für ja, die 0 für nein. Den Output bezeichnen wir\n",
    "mit y. Dann lautet die obige Tabelle für das \"Ist-der-Rasen-nass-Problem\":\n",
    "\n",
    "x1 | x2 | y\n",
    "---|----|---\n",
    "0  | 0  | 0\n",
    "1  | 0  | 1\n",
    "0  | 1  | 1\n",
    "1  | 1  | 1\n",
    "\n",
    "wir schreiben das obige Python-Programm um und verwenden die Integers 0 und 1\n",
    "für die Eingaben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe\n",
    "x1 = int(input('Regnet es (ja = 1 | nein = 0)?'))\n",
    "x2 = int(input('Ist der Rasensprenger eingeschaltet? (ja = 1 | nein = 0)'))\n",
    "\n",
    "# Verarbeitung\n",
    "y = (x1 == 1) or (x2 == 1)\n",
    "\n",
    "# Ausgabe\n",
    "if y == True:\n",
    "    print('Der Rasen wird nass.')\n",
    "else:\n",
    "    print('Der Rasen wird nicht nass.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2b7f6",
   "metadata": {},
   "source": [
    "Nun ersetzen wir das logische ODER durch ein mathematisches Konstrukt:\n",
    "Wenn die Ungleichung\n",
    "\n",
    "$$x_1 \\omega_1  +  x_2 \\omega_2 \\geq \\theta$$\n",
    "\n",
    "erfüllt ist, dann ist $y = 1$ oder anders ausgedrückt, der Rasen wird nass. Und\n",
    "ansonsten ist $y = 0$, der Rasen wird nicht nass. Allerdings müssen wir noch die\n",
    "**Gewichte** $\\omega_1$ und $\\omega_2$ (auf Englisch: weights) geschickt wählen.\n",
    "Die Zahl $\\theta$ ist der griechische Buchstabe Theta und steht als Abkürzung\n",
    "für den sogenannten **Schwellenwert** (auf Englisch: threshold).\n",
    "\n",
    "Beispielsweise $\\omega_1 = 0.3$, $\\omega_2=0.3$ und $\\theta = 0.2$ passen:\n",
    "\n",
    "* $0 \\cdot 0.3 + 0 \\cdot 0.3 = 0.0 \\geq 0.2$ nicht erfüllt\n",
    "* $0 \\cdot 0.3 + 1 \\cdot 0.3 = 0.3 \\geq 0.2$ erfüllt\n",
    "* $1 \\cdot 0.3 + 0 \\cdot 0.3 = 0.3 \\geq 0.2$ erfüllt\n",
    "* $1 \\cdot 0.3 + 1 \\cdot 0.3 = 0.6 \\geq 0.2$ erfüllt\n",
    "\n",
    "Wir schreiben erneut das Python-Programm um und ersetzen das logische ODER durch\n",
    "die linke Seite der Ungleichung. Dann vergleichen wir anschließend mit $0.2$, um\n",
    "zu entscheiden, ob der Rasen nass wird oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eingabe\n",
    "x1 = int(input('Regnet es (ja = 1 | nein = 0)?'))\n",
    "x2 = int(input('Ist der Rasensprenger eingeschaltet? (ja = 1 | nein = 0)'))\n",
    "\n",
    "# Verarbeitung\n",
    "y = 0.3 * x1 + 0.3 * x2\n",
    "\n",
    "# Ausgabe\n",
    "if y >= 0.2:\n",
    "    print('Der Rasen wird nass.')\n",
    "else:\n",
    "    print('Der Rasen wird nicht nass.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f600e0",
   "metadata": {},
   "source": [
    "### Die Heaviside-Funktion ersetzt die Ungleichung\n",
    "\n",
    "Noch sind wir aber nicht fertig, denn auch die Frage \"Ist die Ungleichung\n",
    "erfüllt oder nicht?\" muss noch in eine mathematische Funktion umgeschrieben\n",
    "werden. Dazu subtrahieren wir zuerst auf beiden Seiten der Ungleichung den\n",
    "Schwellenwert $\\theta$:\n",
    "\n",
    "$$-\\theta + x_1 \\omega_1  +  x_2 \\omega_2 \\geq 0.$$\n",
    "\n",
    "Damit haben wir jetzt nicht mehr einen Vergleich mit dem Schwellenwert, sondern\n",
    "müssen nur noch entscheiden, ob der Ausdruck $-\\theta + x_1 \\omega_1 + x_2\n",
    "\\omega_2$ negativ oder positiv ist. Bei negativen Werten, soll $y = 0$ sein und\n",
    "bei positiven Werten (inklusive der Null) soll $y = 1$ sein. Dafür gibt es in\n",
    "der Mathematik eine passende Funktion, die sogenannte\n",
    "[Heaviside-Funktion](https://de.wikipedia.org/wiki/Heaviside-Funktion) (manchmal\n",
    "auch Theta-, Stufen- oder Treppenfunktion genannt).\n",
    "\n",
    "![Schaubild der Heaviside-Funktion](https://gramschs.github.io/book_ml4ing/_images/heaviside_wikipedia.svg)\n",
    "\n",
    "([Quelle:](https://de.wikipedia.org/wiki/Heaviside-Funktion#/media/Datei:Heaviside.svg) \"Verlauf der Heaviside-Funktion auf $\\mathbb{R}$\" von Lennart Kudling. Lizenz: gemeinfrei)\n",
    "\n",
    "Definiert ist die Heaviside-Funktion folgendermaßen:\n",
    "\n",
    "$$\\Phi(x) = \\begin{cases}0:&x<0\\\\1:&x\\geq 0\\end{cases}$$\n",
    "\n",
    "In dem Modul NumPy ist die Heaviside-Funktion schon hinterlegt, siehe\n",
    "> <https://numpy.org/doc/stable/reference/generated/numpy.heaviside.html>\n",
    "\n",
    "Wir visualisieren die Heaviside-Funktion für das Intervall $[-3,3]$ mit 101\n",
    "Punkten. Setzen Sie das zweite Argument einmal auf 0 und einmal auf 2. Was\n",
    "bewirkt das zweite Argument? Sehen Sie einen Unterschied in der Visualisierung?\n",
    "Erhöhen Sie auch die Anzahl der Punkte im Intervall. Wählen Sie dabei immer eine\n",
    "ungerade Anzahl, damit die 0 dabei ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d59458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 101)\n",
    "y0 = np.heaviside(x, 0)  # an der Stelle x=0 ist y=0\n",
    "y1 = np.heaviside(x, 2)  # an der Stelle x=0 ist y=2\n",
    "\n",
    "# Daten für Plotly Express vorbereiten\n",
    "df = pd.DataFrame({'x': x, 'y0': y0, 'y1': y1})\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(df, x='x', y=['y0', 'y1'], title='Heaviside-Funktion')\n",
    "fig.update_layout(\n",
    "    xaxis_title='x',\n",
    "    yaxis_title='y'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead73527",
   "metadata": {},
   "source": [
    "Mit der Heaviside-Funktion können wir nun den Vergleich in der\n",
    "Programmverzweigung mit $0.2$ durch eine direkte Berechnung ersetzen. Schauen\n",
    "Sie sich im folgenden Programm-Code an, wie wir jetzt ohne logisches Oder und\n",
    "ohne Programmverzweigung if-else auskommen.\n",
    "\n",
    "```python\n",
    "# Import der notwendigen Module\n",
    "import numpy as np\n",
    "\n",
    "# Eingabe\n",
    "x1 = int(input('Regnet es (ja = 1 | nein = 0)?'))\n",
    "x2 = int(input('Ist der Rasensprenger eingeschaltet? (ja = 1 | nein = 0)'))\n",
    "\n",
    "# Verarbeitung\n",
    "y = np.heaviside(-0.2 + 0.3 * x1 + 0.3 * x2, 1.0)\n",
    "\n",
    "# Ausgabe\n",
    "ergebnis_als_text = ['Der Rasen wird nicht nass.', 'Der Rasen wird nass.']\n",
    "print(ergebnis_als_text[int(y)])\n",
    "```\n",
    "\n",
    "### Das Perzeptron mit mehreren Eingabewerten\n",
    "\n",
    "Das Perzeptron für zwei Eingabewerte lässt sich in sehr natürlicher Weise auf\n",
    "viele Eingabewerte verallgemeinern, die auch mehrere Zustände annehmen können.\n",
    "Bei den Outputs bleiben wir jedoch dabei, dass nur zwei Zustände angenommen\n",
    "werden können, die wir mit 0 und 1 bezeichnen. Wir betrachten also weiterhin\n",
    "binäre Klassifikationsaufgaben.\n",
    "\n",
    "Wenn wir nicht nur zwei, sondern $n$ Eingabewerte $x_i$ haben, brauchen wir\n",
    "entsprechend auch $n$ Gewichte $\\omega_i$. Die Eingabewerte können wir in einem\n",
    "Spaltenvektor zusammenfassen, also\n",
    "\n",
    "$$\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix}.$$\n",
    "\n",
    "Auch die Gewichte können wir in einem Spaltenvektor zusammenfassen, also\n",
    "\n",
    "$$\\boldsymbol{\\omega} = \\begin{pmatrix} \\omega_1 \\\\ \\omega_2 \\\\ \\vdots \\\\\n",
    "\\omega_n\\end{pmatrix}.$$\n",
    "\n",
    "Nun lässt sich die Ungleichung recht einfach durch das Skalarprodukt abkürzen:\n",
    "\n",
    "$$\\mathbf{x}^{T}\\boldsymbol{\\omega} = x_1 \\omega_1 +  x_2 \\omega_2 + \\ldots +\n",
    "x_n \\omega_n \\geq \\theta.$$\n",
    "\n",
    "Wie bei dem Perzeptron mit zwei Eingängen wird der Schwellenwert $\\theta$ durch\n",
    "Subtraktion auf die linke Seite gebracht. Wenn wir jetzt bei dem Vektor\n",
    "$\\boldsymbol{\\omega}$ mit den Gewichten vorne den Vektor um das Element\n",
    "$\\omega_0 = -\\theta$ ergänzen und den Vektor $\\mathbf{x}$ mit $x_0 = 1$\n",
    "erweitern, dann erhalten wir\n",
    "\n",
    "$$\\mathbf{x}^{T}\\boldsymbol{\\omega} = 1 \\cdot (-\\theta) + x_1 \\omega_1 + x_2\n",
    "\\omega_2 + \\ldots + x_n \\omega_n \\geq 0.$$\n",
    "\n",
    "Genaugenommen hätten wir jetzt natürlich für die Vektoren $\\boldsymbol{\\omega}$\n",
    "und $\\mathbf{x}$ neue Bezeichnungen einführen müssen, aber ab sofort gehen wir\n",
    "immer davon aus, dass die mit dem negativen Schwellenwert $-\\theta$ und $1$\n",
    "erweiterten Vektoren gemeint sind. Der negative Schwellenwert wird übrigens in\n",
    "der ML-Community **Bias** oder **Bias-Einheit (Bias Unit)** genannt.\n",
    "\n",
    "Um jetzt klassfizieren zu können, wird auf die gewichtete Summe\n",
    "$\\mathbf{x}^{T}\\boldsymbol{\\omega}$ die Heaviside-Funktion angewendet. Manchmal\n",
    "wird anstatt der Heaviside-Funktion auch die Signum-Funktion verwendet. Im\n",
    "Folgenden nennen wir die Funktion, die auf die gewichtete Summe angewendet wird,\n",
    "**Aktivierungsfunktion**.\n",
    "\n",
    "**Was ist ... ein Perzeptron?**\n",
    "\n",
    "Das Perzeptron ist ein Modell, das Eingaben verarbeitet, indem es erst eine\n",
    "gewichtete Summe der Eingaben bildet und dann darauf eine Aktivierungsfunktion\n",
    "anwendet.\n",
    "\n",
    "Eine typische Visualisierung des Perzeptrons ist in der folgenden Abbildung\n",
    "{ref}`fig_perzeptron` gezeigt. Die Eingaben werden durch Kreise symbolisiert.\n",
    "Die Multiplikation der Inputs $x_i$ mit den Gewichten $\\omega_i$ wird durch\n",
    " Kanten dargestellt. Die einzelnen Summanden $x_i \\omega_i$ treffen sich\n",
    "sozusagen im mittleren Kreis, wo auf die gewichtete Summe dann eine\n",
    "Aktivierungsfunktion angewendet wird. Das Ergebnis, der Output $\\wedge{y}$ wird\n",
    "dann berechnet und wiederum als Kreis gezeichnet.\n",
    "\n",
    "![Darstellung Perzeptron](https://gramschs.github.io/book_ml4ing/_images/topology_perceptron.svg)\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 12.1\n",
    "\n",
    "In diesem Abschnitt haben wir gelernt, wie ein Perzeptron aufgebaut ist und wie\n",
    "aus den Daten mit Hilfe von Gewichten und einer Aktivierungsfunktion der binäre\n",
    "Zustand prognostiziert wird. Im nächsten Abschnitt beschäftigen wir uns mit der\n",
    "Frage, wie die Gewichte gefunden werden.\n",
    "\n",
    "## 12.2 Die Perzeptron-Lernregel\n",
    "\n",
    "In dem Abschnitt über das Perzeptron waren die Gewichte und der Schwellenwert vorgegeben. Aber wie kommt man dazu? In diesem Abschnitt beschäftigen wir uns damit, wie die Gewichte und der Schwellenwert gewählt werden müssen, damit das Perzeptron seine binäre Klassifikationsaufgabe erfüllen kann.\n",
    "\n",
    "### Lernziele Kapitel 12.2\n",
    "\n",
    "* Sie kennen die drei Phasen, in denen ein Perzeptron trainiert wird:\n",
    "  * Initialisierung der Gewichte und Festlegung der Lernrate;\n",
    "  * Berechnung des prognostizierten Outputs und Aktualisierung der Gewichte sowie\n",
    "  * Terminierung des Trainings.\n",
    "* In Zusammenhang mit dem Training von ML-Verfahren kennen Sie die Fachbegriffe Lernrate und Epoche.\n",
    "\n",
    "### Hebbsche Regel\n",
    "\n",
    "Kaum zu glauben, aber die Idee zum Lernen der Gewichte eines Perzeptrons stammt\n",
    "nicht von Informatiker:innen, sondern von einem Psychologen namens [Donald\n",
    "Olding Hebb](https://de.wikipedia.org/wiki/Donald_O._Hebb). Im Englischen wird\n",
    "seine Arbeit meist durch das Zitat\n",
    "\n",
    ">\"what fires together, wires together\"\n",
    "\n",
    "kurz zusammengefasst. Hebb hat die Veränderung der synaptischen Übertragung von\n",
    "Neuronen untersucht und dabei festgestellt, dass je häufiger zwei Neuronen\n",
    "gemeinsam aktiv sind, desto eher werden die beiden aufeinander reagieren.\n",
    "\n",
    "Die Hebbsche Regel wird beim maschinellen Lernen dadurch umgesetzt, dass der\n",
    "Lernprozess mit zufälligen Gewichten startet und dann der prognostizierte Output\n",
    "mit dem echten Output verglichen wird. Je nachdem, ob der echte Output erreicht\n",
    "wurde oder nicht, werden nun die Gewichte und damit der Einfluss eines einzelnen\n",
    "Inputs verstärkt oder nicht. Dieser Prozess — Vergleichen und Abändern der\n",
    "Gewichte — wird solange wiederholt, bis die passenden Gewichte gefunden sind.\n",
    "\n",
    "Angenommen, in unserem \"Ist-der-Rasen-nass-Problem\" sind die Gewichte alle Null,\n",
    "also $\\omega_0 = \\omega_1 = \\omega_2 = 0$. Was prognostiziert das Perzeptron für\n",
    "\"es regnet nicht\" ($x_1=0$) und \"der Rasensprenger ist aus\" ($x_2=0$)?\n",
    "\n",
    "Das Perzeptron prognostiziert fälschlicherweise, dass der Rasen nass ist. Die\n",
    "gewichtete Summe wird zu\n",
    "\n",
    "$$\\mathbf{x}^{T} \\boldsymbol{\\omega} = \\begin{pmatrix} 0, 0, 0 \\end{pmatrix}\n",
    "\\cdot \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = 0$$\n",
    "\n",
    "berechnet. Da aber dann noch die Aktivierungsfunktion (Heaviside-Funktion)\n",
    "angewendet werden muss, erhalten wir\n",
    "\n",
    "$$\\Phi(0)=1,$$\n",
    "\n",
    "also der Rasen ist nass.\n",
    "\n",
    "### Lernregel für das Perzeptron\n",
    "\n",
    "Wie werden die Gewichte konkret verstärkt oder abgeschwächt, wenn der\n",
    "prognostizierte Output nicht mit dem echten Output übereinstimmt? Die Lernregel\n",
    "für das Perzeptron sieht zunächst einmal kompliziert aus:\n",
    "\n",
    "$$\\omega_i^{\\text{neu}} = \\omega_i^{\\text{aktuell}} + \\alpha \\cdot(y -\n",
    "\\hat{y}^{\\text{aktuell}}) \\cdot x_i.$$\n",
    "\n",
    "Gehen wir die Rechenvorschrift Stück für Stück durch. Zunächst einmal fällt auf,\n",
    "dass ein Index $i$ auftaucht. Das liegt daran, dass wir mehrere Eingabewerte\n",
    "haben und damit mehrere Gewichte — ein Gewicht pro Eingabewert. Da die\n",
    "Lernvorschrift allgemeingültig formuliert werden soll, gehen wir jetzt einfach\n",
    "mal davon aus, dass wir $m$ verschiedene Eingabewerte haben. $x_i$ meint also\n",
    "den i-ten Eingabewert und mit $\\omega_i$ bezeichnen wir das dazugehörige\n",
    "Gewicht. Dabei dürfen wir den Bias nicht vergessen.\n",
    "\n",
    "Bisher hatten wir den Output einfach mit $y$ gekennzeichnet. Jetzt müssen wir\n",
    "aber etwas sorgfältiger vorgehen und genau unterscheiden, ob wir den Output\n",
    "meinen, den das Perzeptron prognostiziert oder den echten (gemessenen) Output.\n",
    "Über berechnete bzw. prognostizierte Outputs setzen wir ein kleines Dachsymbol\n",
    "$\\wedge$. Etwas präziser bezeichnen wir den prognostizierten Output, den das\n",
    "Perzeptron mit den aktuellen Gewichten $(\\omega_0^{\\text{aktuell}},\n",
    "\\omega_1^{\\text{aktuell}}, \\ldots, \\omega_m^{\\text{aktuell}})$ berechnen würde,\n",
    "mit der Abkürzung $\\hat{y}^{\\text{aktuell}}$ . Für den echten Output bleiben wir\n",
    "einfach bei der Bezeichnung $y$.\n",
    "\n",
    "Fehlt noch das $\\alpha$, doch dazu kommen wir gleich. Schauen wir uns erst\n",
    "einmal an, wie sich die Differenz $y - \\hat{y}^{\\text{aktuell}}$ auf die\n",
    "Verstärkung oder Abschwächung der Gewichte auswirkt.\n",
    "\n",
    "Wenn der echte Output und der prognostizierte Output gleich sind, ist deren\n",
    "Differenz Null und es ändert sich nichts. Ansonsten gibt es zwei Möglichkeiten:\n",
    "\n",
    "* Wenn der *echte Output größer ist als der prognostizierte Output*, dann ist\n",
    "  $y - \\hat{y}^{\\text{aktuell}} > 0$. Indem wir nun zu den alten Gewichten den Term\n",
    "  $ \\alpha \\cdot(y - \\hat{y}^{\\text{aktuell}})$ addieren, verstärken wir die\n",
    "  alten Gewichte. Dabei berücksichtigen wir, ob der Input überhaupt einen\n",
    "  Beitrag zum Output liefert, indem wir zusätzlich mit $x_i$ multiplizieren. Ist\n",
    "  nämlich der Input $x_i=0$, wird so nichts an den Gewichten geändert.\n",
    "* Ist jedoch *der echte Output kleiner als der prognostizierte Output*, dann ist\n",
    "  $y - \\hat{y}^{\\text{aktuell}} < 0$. Daher werden nun die alten Gewichte durch\n",
    "  die Addition des negativen Terms $\\alpha \\cdot(y - \\hat{y}^{\\text{aktuell}})\n",
    "  \\cdot x_i$ abgeschwächt.\n",
    "\n",
    "Damit die Schritte zwischen der Abschwächung und der Verstärkung nicht zu groß\n",
    "werden, werden sie noch mit einem Vorfaktor $\\alpha$ multipliziert, der zwischen\n",
    "0 und 1 liegt. Ein typischer Wert von $\\alpha$ ist $0.0001$. Dieser Vorfaktor\n",
    "$\\alpha$ wird **Lernrate** genannt.\n",
    "\n",
    "**Was ist ... die Lernrate?**\n",
    "\n",
    "Die Lernrate ist eine Zahl, die zu Beginn des ML-Trainings gesetzt wird (ein\n",
    "sogenannter Hyperparameter). Sie bestimmt, wie stark die neuen Gewichte auf\n",
    "Fehler zwischen Prognose und tatsächlichem Output des aktuellen Durchgangs\n",
    "reagieren.\n",
    "\n",
    "### Perzeptron-Training am Beispiel des logischen ODER\n",
    "\n",
    "Das logische Oder ist bereits durch die Angabe der folgenden vier Datensätzen\n",
    "komplett definiert. Dabei haben wir noch die Bias-Einheit $x_0=1$ ergänzt.\n",
    "\n",
    "x0 | x1 | x2 | y\n",
    "---|---|----|---\n",
    "1  | 0 | 0  | 0\n",
    "1  | 0 | 1  | 1\n",
    "1  | 1 | 0  | 1\n",
    "1  | 1 | 1  | 1\n",
    "\n",
    "Im Folgenden wird das Training eines Perzeptrons Schritt für Schritt vorgerechnet.\n",
    "\n",
    "#### Schritt 1: Initialisierung der Gewichte und der Lernrate\n",
    "\n",
    "Wir brauchen für die drei Inputs drei Gewichte und setzen diese drei Gewichte\n",
    "jeweils auf 0. Wir sammeln die Gewichte als Vektor, also\n",
    "\n",
    "$$\\boldsymbol{\\omega} = \\begin{pmatrix}\\omega_0 \\\\ \\omega_1 \\\\ \\omega_2\\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0\\end{pmatrix}.$$\n",
    "\n",
    "Darüber hinaus müssen wir uns für eine Lernrate $\\alpha$ entscheiden. Obwohl\n",
    "normalerweise ein kleiner (aber positiver) Wert gewählt wird, setzen wir der\n",
    "Einfachheit halber die Lernrate auf 1, also $\\alpha = 1$.\n",
    "\n",
    "#### Schritt 2: Berechnung des Outputs und ggf. Anpassung der Gewichte\n",
    "\n",
    "Wir setzen nun solange nacheinander den ersten, zweiten, dritten und vierten\n",
    "Trainingsdatensatz in die Berechnungsvorschrift unseres Perzeptrons ein, bis die\n",
    "Gewichte für alle vier Trainingsdatensätze zu einer korrekten Prognose führen.\n",
    "Zur Erinnerung, wir berechnen den aktuellen Output des Perzeptrons mit der\n",
    "Formel\n",
    "\n",
    "$$\\hat{y}^{aktuell} = \\Phi(\\mathbf{x}^{T}\\boldsymbol{\\omega}) = \\Phi(x_0\n",
    "\\omega_0 + x_1 \\omega_1 + x_2 \\omega_2 ).$$\n",
    "\n",
    "Blättern Sie Seite für Seite durch. Jede Seite entspricht einem Durchgang. Ein\n",
    "Durchgang wird im ML (wie auch in der Mathematik) als eine **Iteration**\n",
    "bezeichnet.\n",
    "\n",
    "![Lernregel am Beispiel](https://gramschs.github.io/book_ml4ing/chapter12/sec02.html#schritt-2-berechnung-des-outputs-und-ggf-anpassung-der-gewichte)\n",
    "\n",
    "#### Schritt 3: Terminierung\n",
    "\n",
    "Die letzten vier Iterationen mit den Gewichten $(-1,1,1)$ prognostizierten\n",
    "jeweils das richtige Ergebnis. Daher können wir nun mit den Iterationen stoppen.\n",
    "\n",
    "Insgesamt brauchten wir 13 Iterationen, bis wir die Gewichte für unser\n",
    "Perzeptron gefunden haben. Die finalen Gewichte haben wir bereits nach neun\n",
    "Iterationen gefunden. Weitere vier Iterationen brauchten wir, um zu überprüfen,\n",
    "ob das Perzeptron die vier Datensätze korrekt prognostiziert. Oder anders\n",
    "ausgedrückt, mussten alle vier Datensätze noch einmal durchlaufen werden. Das\n",
    "Durchlaufen aller Datensätze kommt beim mschinellen Lernen häufig vor, so dass\n",
    "es dafür einen eigenen Fachbegriff gibt, nämlich die Epoche.\n",
    "\n",
    "**Was ist ... eine Epoche?**\n",
    "\n",
    "Das komplette Durchlaufen aller Trainingsdaten wird eine Epoche genannt.\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 12.2\n",
    "\n",
    "In diesem Abschnitt haben wir uns mit dem händischen Training eines Perzeptrons\n",
    "beschäftigt. Als nächstes werden wir dazu eine Bibliothek kennenlernen, die\n",
    "diese Arbeit für uns übernimmt.\n",
    "\n",
    "## 12.3 Training eines Perzeptrons mit Scikit-Learn\n",
    "\n",
    "Nachdem wir im letzten Abschnitt ein Perzeptron händisch für die\n",
    "Klassifikationsaufgabe des logischen Oders trainiert haben, benutzen wir nun\n",
    "Scikit-Learn.\n",
    "\n",
    "### Lernziele Kapitel 12.3\n",
    "\n",
    "* Sie können das Perzeptron-Modell von Scikit-Learn laden und mit den gegebenen\n",
    "  Trainingsdaten trainieren.\n",
    "* Sie wissen, wie Sie auf die Gewichte des gelernten Modells zugreifen.\n",
    "\n",
    "### Das logische Oder Klassifikationsproblem - diesmal mit Scikit-Learn\n",
    "\n",
    "Im letzten Abschnitt haben wir händisch ein Perzeptron trainiert. Zur\n",
    "Erinnerung, wenn wir die Bias-Einheit weglassen, lautet das logische Oder in\n",
    "Tabellenform wie folgt:\n",
    "\n",
    "x1 | x2 | y\n",
    "---|----|---\n",
    " 0 | 0  | 0\n",
    " 0 | 1  | 1\n",
    " 1 | 0  | 1\n",
    " 1 | 1  | 1\n",
    "\n",
    "Diese Daten packen wir in ein DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48541cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data =  pd.DataFrame({'x1' : [0, 0, 1, 1], 'x2'  : [0, 1, 0, 1], 'y' : [0, 1, 1, 1]})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2888610",
   "metadata": {},
   "source": [
    "Nun wählen wir das Perzeptron als das zu trainierende ML-Modell aus. Direkt beim\n",
    "Laden des Modells legen wir die Hyperparameter des Modells fest. Welche\n",
    "Hyperparameter ein Modell hat, steht in der\n",
    "[Perzeptron-Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html?highlight=perceptron#sklearn.linear_model.Perceptron).\n",
    "In diesem Fall wäre beispielsweise die Lernrate ein Hyperparameter. Laut\n",
    "Dokumentation wird die Lernrate beim Scikit-Learn-Perzeptron mit `eta0`\n",
    "bezeichnet. Der Python-Code, um das Perzeptron-Modell mit einer Lernrate von 1\n",
    "zu laden, lautet also wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "model = Perceptron(eta0 = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe62e0",
   "metadata": {},
   "source": [
    "Nun können wir das Perzeptron-Modell mit den Input- und Outputdaten trainieren,\n",
    "indem wir die `.fit()`-Methode aufrufen. Zuvor bereiten wir die Daten noch\n",
    "passend für das Perzeptron auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['x1', 'x2']]\n",
    "y = data['y']\n",
    "\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166f071",
   "metadata": {},
   "source": [
    "Nachdem wir den letzten Python-Befehl ausgeführt haben, passiert scheinbar\n",
    "nichts. Nur der Klassenname `Perceptron()` des Objekts `model` wird ausgegeben\n",
    "(wenn Sie den Code interaktiv ausführen). Intern wurde jedoch das\n",
    "Perzeptron-Modell trainiert, d.h. die Gewichte des Perzeptrons wurden iterativ\n",
    "bestimmt. Die Gewichte sind nun in dem Objekt `model` gespeichert. Davon können\n",
    "wir uns überzeugen, indem wir auf die Attribute des Objekts zugreifen und diese\n",
    "anzeigen lassen. Die Gewichte sind in dem Attribut `.coef_` gespeichert, während\n",
    "das Gewicht der Bias-Einheit sich im Attribut `.intercept_` befindet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880575a",
   "metadata": {},
   "source": [
    "Zuletzt können wir das trainierte Perzeptron-Modell Prognosen treffen lassen.\n",
    "Was prognostiziert das Modell beispielsweise für $x_1=0$ und $x_2=1$? Das\n",
    "tatsächliche Ergebnis der logischen Oder-Verknüpfung ist $y=1$, was liefert das\n",
    "Perzeptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prognose = model.predict([[0, 1]])\n",
    "print(y_prognose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d294db9",
   "metadata": {},
   "source": [
    "Wir können auch gleich für alle Datensätze eine Prognose erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prognose = model.predict(X)\n",
    "print(y_prognose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063242d",
   "metadata": {},
   "source": [
    "Tatsächlich funktioniert unser trainiertes Perzeptron zu 100 % korrekt und ist\n",
    "damit validiert. Bei nur vier Datensätzen lässt sich relativ leicht überblicken,\n",
    "dass alle vier Prognosen korrekt sind. Sobald die Datenanzahl zunimmt, wird es\n",
    "schwieriger, den Überblick zu behalten. Daher stellt Scikit-Learn die Methode\n",
    "`.score()` zur Verfügung, die bei Klassifikatoren die Anzahl der korrekt\n",
    "prognostizierten Outputs im Verhältnis zur Gesamtanzahl berechnet. Das Ergbnis\n",
    "ist also eine Bewertung zwischen 0 (keine einzige korrekte Prognose) und 1\n",
    "(perfekt Prognose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6546b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genauigkeit = model.score(X, y)\n",
    "print(genauigkeit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ee3f2",
   "metadata": {},
   "source": [
    "### Erkennung von Brustkrebs\n",
    "\n",
    "Als nächstes betrachten wir einen sehr bekannten ML-Datensatz, nämlich Daten zur\n",
    "Erkennung von Brustkrebs, siehe\n",
    "<https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren des Breast Cancer Datensatzes aus Scikit-Learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "data = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n",
    "                  columns= np.append(cancer['feature_names'], ['target']))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c68b9",
   "metadata": {},
   "source": [
    "Wie immer berschaffen wir uns einen Überblick über die statistischen Kennzahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e32374",
   "metadata": {},
   "source": [
    "Für das Training des Perzeptrons teilen wir die Daten in Trainings- und Testdaten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a49866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = data_train.loc[:, 'mean radius' : 'worst fractal dimension']\n",
    "X_test  = data_test.loc[:, 'mean radius' : 'worst fractal dimension']\n",
    "\n",
    "y_train = data_train['target']\n",
    "y_test = data_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce2aae",
   "metadata": {},
   "source": [
    "Nun laden wir das Perzeptron-Modell und trainieren es mit den Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Perceptron model\n",
    "model = Perceptron(eta0=0.1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdc258",
   "metadata": {},
   "source": [
    "Wie üblich können wir es nun zu Prognosen nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_test_prognose = model.predict(X_test)\n",
    "print(y_test_prognose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d2d918",
   "metadata": {},
   "source": [
    "Vor allem aber die systematische Bestimmung der Scores für Trainingsdaten und\n",
    "Testdaten ist interessant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = model.score(X_train, y_train)\n",
    "score_test = model.score(X_test, y_test)\n",
    "\n",
    "print(f'Score Trainingsdaten: {score_train}')\n",
    "print(f'Score Testdaten: {score_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79ee64",
   "metadata": {},
   "source": [
    "Wir könnten vermuten, dass wir bereits im Bereich des Overfittings sind.\n",
    "Allerdings ist auch die Initialisierung der Zufallszahlen fixiert. Ohne\n",
    "`random_state=42` kommen andere Scores für Trainings- und Testdaten heraus, so\n",
    "dass wir das Perzeptron-Modell zunächst für eine erste Schätzung nehmen dürfen.\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 12.3\n",
    "\n",
    "Mit Scikit-Learn steht schon eine Implementierung des Perzeptrons zur Verfügung,\n",
    "die auch bei größeren Datenmengen eine binäre Klassifikation erlaubt. Welche\n",
    "Daten dabei überhaupt binär klassifiziert können, klären wir in einem der\n",
    "folgenden Abschnitte.\n",
    "\n",
    "## Übung\n",
    "\n",
    "Der folgende Datensatz `automarkt_polen_DE.csv` enthält die Preise und\n",
    "Eigenschaften von Autos aus Polen. Das Jahr bezieht sich auf die Erstzulassung\n",
    "der Autos. Stadt bzw. Region beziehen sich auf den Verkaufsort des Autos. Die\n",
    "übrigen Eigenschaften sind selbsterklärend und ggf. mit ihren Einheiten\n",
    "angegeben.\n",
    "\n",
    "Bearbeiten Sie die folgenden Aufgaben. Vorab können Sie die folgenden Module\n",
    "importieren. Schreiben Sie Ihre Antworten in eine Markdown-Zelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron\n",
    "# from sklearn.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "# from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "# from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "# from sklearn.svm  import SVC, SVR\n",
    "# from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3a0bf",
   "metadata": {},
   "source": [
    "### Aufgabe 1: Import und Bereinigung der Daten\n",
    "\n",
    "Importieren Sie die Daten 'automarkt_polen_DE.csv'. Verschaffen Sie sich einen\n",
    "Überblick und beantworten Sie folgende Fragen:\n",
    "\n",
    "* Wie viele Autos enthält die Datei?\n",
    "* Wie viele Attribute/Eigenschaften/Features sind in den Daten enthalten?\n",
    "* Sind alle Einträge gültig? Wenn nein: welche Eigenschaften sind unvollständig\n",
    "  und wie viele Einträge dieser Eigenschaft sind nicht gültig?\n",
    "* Welches sind die kategorialen/diskreten/qualitativen Eigenschaften und welches\n",
    "  die numerischen/quantititaven Eigenschaften?\n",
    "* Welchen Datentyp haben die einzelnen Attribute/Eigenschaften/Features?\n",
    "\n",
    "Falls der Datensatz ungültige Werte aufweist oder Unstimmigkeiten enthält,\n",
    "bereinigen Sie ihn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dd025",
   "metadata": {},
   "source": [
    "### Aufgabe 2: Statistische Kennzahlen der numerischen Eigenschaften\n",
    "\n",
    "* Ermitteln Sie von den numerischen Eigenschaften die statistischen Kennzahlen\n",
    "  und visualisieren Sie sie. Verwenden Sie beim Plot eine aussagefähige\n",
    "  Beschriftung.\n",
    "* Interpretieren Sie jede Eigenschaft anhand der statistischen Kennzahlen und\n",
    "  der Plots.\n",
    "* Bereinigen Sie bei Ungereimtheiten den Datensatz weiter.\n",
    "* Entfernen Sie Ausreißer.\n",
    "* Beantworten Sie folgende Fragen:\n",
    "  * In welchem Jahr wurden die meisten Autos zugelassen?\n",
    "  * Wie viele Autos wurden in diesem Jahr mit den meisten Zulassungen zugelassen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0806e62",
   "metadata": {},
   "source": [
    "### Aufgabe 3: Statistische Kennzahlen (kategoriale Eigenschaften)\n",
    "\n",
    "Beantworten Sie durch Datenanalyse die folgenden Fragen. Fassen Sie die\n",
    "Ergebnisse bzw. die Interpretation davon jeweils kurz zusammen (als Kommentar in\n",
    "der Code-Zelle oder in einer Markdown-Zelle).\n",
    "\n",
    "* Welche Automarke wird momentan in Polen am häufigsten und welche Automarke am\n",
    "  seltesten zum Verkauf angeboten? Geben Sie jeweils die Anzahl an.\n",
    "* Visualisieren Sie die Anzahl der Autos pro Marke. Beschriften Sie das Diagramm\n",
    "  mit einem aussagefähigen Titel.\n",
    "* Analysieren Sie die Regionen. Gibt es Regionen, die Sie überraschen? Wenn ja,\n",
    "  warum?\n",
    "* Wie viel Prozent der Autos haben ein Automatik-Getriebe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50540b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd8733",
   "metadata": {},
   "source": [
    "### Aufgabe 4: Regression\n",
    "\n",
    "Ziel der Regressionsaufgabe ist es, den Preis der Autos zu prognostizieren.\n",
    "\n",
    "* Wählen Sie zwei Regressionsmodelle aus. Begründen Sie Ihre Auswahl mit einer\n",
    "  Scattermatrix.\n",
    "* Adaptieren Sie die Daten jeweils passend zu den von Ihnen gewählten Modellen.\n",
    "* Falls notwendig, skalieren Sie die Daten.\n",
    "* Führen Sie einen Split der Daten in Trainings- und Testdaten durch.\n",
    "* Trainieren Sie jedes ML-Modell.\n",
    "* Validieren Sie jedes ML-Modell bzgl. der Trainingsdaten und der Testdaten.\n",
    "* Bewerten Sie abschließend: welches der zwei Modelle würden Sie empfehlen?\n",
    "  Begründen Sie Ihre Empfehlung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e02d9",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Ziel der Klassifikationsaufgabe ist es, die Preisklasse \"billig\" oder \"teuer\"\n",
    "der Autos zu prognostizieren.\n",
    "\n",
    "Achtung Vorbereitung:\n",
    "Filtern Sie die Daten nach den Autos, deren Preis kleiner oder gleich dem\n",
    "Median aller Preise ist. Diese Autos sollen als \"billig\" klassfiziert\n",
    "werden. Autos, deren Preis größer als der Median aller Preise ist, sollen\n",
    "als \"teuer\" klassifiziert werden.\n",
    "\n",
    "* Wählen Sie die folgenden Eigenschaften aus: **Jahr** und **Kilometerstand\n",
    "  [km]**.\n",
    "* Adaptieren Sie die Daten passend.\n",
    "* Falls notwendig, skalieren Sie die Daten.\n",
    "* Trainieren Sie einen Entscheidungsbaum (Decision Tree). Begrenzen Sie dabei\n",
    "  die maximale Tiefe des Baumes auf 2.\n",
    "* Visualisieren Sie den Entscheidungsbaum (Decision Tree) inklusive Beschriftung\n",
    "  der Labels.\n",
    "* Bewerten Sie abschließend: Ist das Jahr oder der Kilometerstand wichtiger für\n",
    "  die Einstufung als billiges oder teures Auto? Begründen Sie Ihre Entscheidung\n",
    "  anhand des Entscheidungsbaumes (Decision Trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
