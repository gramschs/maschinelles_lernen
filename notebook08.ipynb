{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69949e91",
   "metadata": {},
   "source": [
    "# 8. ML-Workflow: Datenvorverarbeitung\n",
    "\n",
    "## 8.1 Fehlende Daten\n",
    "\n",
    "Realistische Datensätze sind oft unvollständig. In einer Umfrage hat eine Person\n",
    "mit einer Frage nichts anfangen können und daher nichts angekreuzt. Ein\n",
    "Messsensor an der Produktionsanlage ist abends ausgefallen, was erst am nächsten\n",
    "Morgen bemerkt wurde. Die Mitarbeitenden einer Arztpraxis sind im Urlaub und\n",
    "lassen die Meldung der verabreichten Impfungen noch bis nach dem Urlaub liegen.\n",
    "Es gibt viele Gründe, warum Datensätze unvollständig sind. In diesem Abschnitt\n",
    "beschäftigen eir uns damit, fehlende Daten aufzuspüren und lernen einfache\n",
    "Methoden kennen, damit umzugehen.\n",
    "\n",
    "### Lernziele Kapitel 8.1\n",
    "\n",
    "* Sie können in einem Datensatz mit **isnull()** fehlende Daten aufspüren und\n",
    "  analysieren.\n",
    "* Sie kennen die beiden grundlegenen Strategien, mit fehlenden Daten umzugehen:\n",
    "  * **Elimination** (Löschen) und\n",
    "  * **Imputation** (Vervollständigen).\n",
    "* Sie können Daten gezielt mit **drop()** löschen.\n",
    "* Sie können fehlende Daten mit **fillna()** vervollständigen.\n",
    "\n",
    "### Fehlende Daten aufspüren mit isnull()\n",
    "\n",
    "Wir arbeiten im Folgenden mit einem echten Datensatz der Verkaufsplattform\n",
    "[Autoscout24.de](https://www.autoscout24.de), der Verkaufsdaten zu 1000 Autos\n",
    "enthält. Sie können die csv-Datei hier herunterladen:\n",
    "<https://gramschs.github.io/book_ml4ing/data/autoscout24_fehlende_daten.csv>\n",
    "und in das Jupyter Notebook importieren. Alternativ können Sie die csv-Datei\n",
    "auch über die URL importieren, wie es in der folgenden Code-Zelle gemacht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2002ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://gramschs.github.io/book_ml4ing/data/autoscout24_fehlende_daten.csv'\n",
    "daten = pd.read_csv(url)\n",
    "\n",
    "daten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d50ca",
   "metadata": {},
   "source": [
    "Wir hatten bereits festgestellt, dass die Anzahl der `non-null`-Einträge für die\n",
    "verschiedenen Merkmale unterschiedlich ist. Offensichtlich ist nur bei 963 Autos\n",
    "eine »Farbe« eingetragen und die »Leistung (PS)« ist nur bei 987 Autos gültig.\n",
    "Am wenigsten gültige Einträge hat das Merkmal »Verbrauch (l/100 km)«, wohingegen\n",
    "bei der Eigenschaft »Kilometerstand (km)« nur ein ungültiger Eintrag auftaucht.\n",
    "Welche Einträge ungültig sind, können wir mit der Methode `isnull()` bestimmen.\n",
    "Die Methode liefert ein Pandas DataFrame zurück, das True/False-Werte enthält.\n",
    "True steht dabei dafür, dass ein Wert fehlt bzw. mit dem Eintrag `NaN`\n",
    "gekennzeichnet ist (= not a number). Weitere Details finden Sie in der\n",
    "[Pandas-Dokumentation →\n",
    "isnull()](https://pandas.pydata.org/docs/reference/api/pandas.isnull.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61d535",
   "metadata": {},
   "source": [
    "Bereits in der zweiten Zeile befindet sich ein Auto, bei dem das Merkmal\n",
    "»Verbrauch (l/100 km)« nicht gültig ist (ggf. müssen Sie weiter nach rechts\n",
    "scrollen), den dort steht `True`. Wir betrachten uns diesen Eintrag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten.loc[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3238a",
   "metadata": {},
   "source": [
    "Bei dem Auto handelt es sich um einen Hybrid, vielleicht wurde deshalb der\n",
    "»Verbrauch (l/100 km)« nicht angegeben. Ist das vielleicht auch bei den anderen\n",
    "Autos der Grund? Wir speichern zunächst die isnull()-Datenstruktur in einer\n",
    "eigenen Variable ab und ermitteln zunächst, wie viele Autos keinen gültigen\n",
    "Eintrag bei diesem Merkmal haben. Dazu nutzen wir aus, dass der boolesche Wert\n",
    "`False` bei Rechnungen als 0 interpretiert wird und der boolesche Wert `True`\n",
    "als 1. Die Methode `.sum()` summiert pro Spalte alle Werte, so dass sie direkt\n",
    "die Anzahl der ungültigen Werte pro Spalte liefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ebdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fehlende_daten = daten.isnull()\n",
    "\n",
    "fehlende_daten.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa52b0",
   "metadata": {},
   "source": [
    "Jetzt lassen wir uns diese 109 Autos anzeigen, bei denen ungültige Werte beim\n",
    "»Verbrauch (l/100 km)« angegeben wurden. Dazu nutzen wir die True-Werte in der\n",
    "Spalte `Verbrauch (l/100 km)` als Filter für den ursprünglichen Datensatz.\n",
    "Zumindest die ersten 20 Autos lassen wir uns dann mit der `.head(20)`-Methode\n",
    "anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "autos_mit_fehlendem_verbrauch_pro_100km = daten[ fehlende_daten['Verbrauch (l/100 km)'] == True ]\n",
    "autos_mit_fehlendem_verbrauch_pro_100km.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198c4e2",
   "metadata": {},
   "source": [
    "Bemerkung: Der Vergleich `== True` ist redundant und kann auch weggelassen werden.\n",
    "\n",
    "Beim Kraftstoff werden alle möglichen Angaben gemacht: Hybrid, Benzin, Diesel\n",
    "und Elektro. Wir müssten jetzt systematisch den fehlenden Angaben nachgehen. Für\n",
    "Elektrofahrzeuge und ggf. Hybridautos ist die Angabe »Verbrauch (l/ 100 km)«\n",
    "unsinnig. Aber das zweite Auto mit der Nr. 5 wird mit Benzin betrieben, da\n",
    "scheint Nachlässigkeit beim Ausfüllen der Merkmale vorzuliegen. Beim fünften\n",
    "Auto mit der Nr. 77 ist zwar der »Verbrauch (l/100 km)« nicht angegeben, aber\n",
    "dafür der »Verbrauch (g/km)«. Daraus könnten wir den »Verbrauch (l/100 km)«\n",
    "abschätzen und den fehlenden Wert ergänzen. Es gibt verschiedene Strategien, mit\n",
    "fehlenden Daten umzugehen. Die beiden wichtigsten Verfahren zum Umgang mit\n",
    "fehlenden Daten sind\n",
    "\n",
    "1. Löschen (Elimination) und\n",
    "2. Vervollständigung (Imputation).\n",
    "\n",
    "Bei Elimination werden Datenpunkte (Autos) und/oder Merkmale gelöscht. Bei\n",
    "Imputation (Vervollständigung) werden die fehlenden Werte ergänzt. Beide\n",
    "Verfahren werden wir nun etwas detaillierter betrachten.\n",
    "\n",
    "### Löschen (Elimination) mit drop()\n",
    "\n",
    "Bei der Elimination (Löschen) können wir filigran vorgehen oder die\n",
    "Holzhammer-Methode verwenden. Beispielsweise könnten wir entscheiden, das\n",
    "Merkmal »Verbrauch (l/100 km)« komplett zu löschen und einfach nur den\n",
    "»Verbrauch (g/km)« zu berücksichtigen. Aber ein kurzer Blick auf die Daten hatte\n",
    "ja bereits gezeigt, dass diese Werte auch nur unzuverlässig gefüllt waren, auch\n",
    "wenn sie technisch gültig sind. Wir löschen beide Merkmale. Dazu benutzen wir\n",
    "die Methode `drop()` mit dem zusätzlichen Argument `columns=['Verbrauch (l/\n",
    "100 km)', 'Verbrauch (g/km)']`. Da wir gleich zwei Spalten aufeinmal eliminieren\n",
    "möchten, müssen wir die Spalten (Columns) als Liste übergeben. Danach überprüfen\n",
    "wir mit der Methode `.info()`, ob das Löschen geklappt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten.drop(columns=['Verbrauch (l/100 km)', 'Verbrauch (g/km)'])\n",
    "daten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335231a5",
   "metadata": {},
   "source": [
    "Leider hat der Befehl `drop()` nicht funktioniert! Was ist da los? Python und\n",
    "Pandas verfolgen das Programmierparadigma »Explizit ist besser als implizit!«\n",
    "Daher werden zwar werden durch den `drop()`-Befehl die beiden Spalten gelöscht,\n",
    "aber der Datensatz `daten` selbst bleibt aus Sicherheitsgründen unverändert.\n",
    "Möchten wir den Datensatz mit den gelöschten Merkmalen weiter verwenden, müssen\n",
    "wir ihn in einer neuen Variable speichern oder die alte Variable `daten` damit\n",
    "überschreiben. Wir nehmen eine neue Variable namens `daten_ohne_verbrauch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch = daten.drop(columns=['Verbrauch (l/100 km)', 'Verbrauch (g/km)'])\n",
    "daten_ohne_verbrauch.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f0ff6",
   "metadata": {},
   "source": [
    "Ein weiterer Datenpunkt weist einen ungültigen Eintrag für den »Kilometerstand\n",
    "(km)« auf. Schauen wir zunächst nach, um welches Auto es sich handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch[ daten_ohne_verbrauch['Kilometerstand (km)'].isnull() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca4024",
   "metadata": {},
   "source": [
    "Bei den Einträgen des Autos sind noch mehr Probleme ersichtlich. Die\n",
    "Erstzulassung war sicherlich nicht bei 37.500 km und das Jahr ist nicht 12/2020.\n",
    "Wir können jetzt diesen Datenpunkt löschen oder den Datenpunkt reparieren.\n",
    "Zunächst einmal der Code zum Löschen des Datenpunktes. Standardmäßig löscht die\n",
    "`drop()`-Methode ohnehin Zeilen, also Datenpunkte, so dass wir ohne weitere\n",
    "Optionen den Index der zu löschenden Datenpunkte angeben. Diesmal verwenden wir\n",
    "die alte Variable um den reduzierten Datensatz zu speichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fa7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch = daten_ohne_verbrauch.drop(708)\n",
    "daten_ohne_verbrauch.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88eb62",
   "metadata": {},
   "source": [
    "Wie Sie in der [Dokumentation Scikit-Learn →\n",
    "drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
    "nachlesen können, gibt es zum expliziten Überschreiben der alten Variable auch\n",
    "die Alternative, die Option `inplace=True` zu setzen. Welche Option Sie nutzen,\n",
    "ist Geschmackssache.\n",
    "\n",
    "Ob alle Angaben plausibel sind, ist nicht gesagt. Bei dem Peugeot mit dem Index\n",
    "708 hatten wir ja gesehen, dass bei der Erstzulassung eine Kilometerangabe\n",
    "stand. Tatsächlich gab es bereits erste Hinweise darauf, dass manche Werte\n",
    "technisch gültig, aber nicht plausibel sind. Die Spalte mit dem Jahr\n",
    "beispielsweise wurde beim Import als Datentyp Object klassifiziert. Zu erwarten\n",
    "wäre jedoch der Datentyp Integer gewesen. Schauen wir noch einmal in den\n",
    "ursprünglichen Datensatz hinein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten['Jahr'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce14147",
   "metadata": {},
   "source": [
    "Da bei dem Peugeot mit dem Index 708 das Jahr fälschlicherweise mit `12/2020`\n",
    "angegeben wurde, hat dieser eine Text-Eintrag dazu geführt, dass die komplette\n",
    "Spalte als Object klassifiziert wurde und nicht als Integer. Daher müssen stets\n",
    "weitere Plausibilitätsprüfungen durchgeführt werden, bevor die Daten genutzt\n",
    "werden, um statistische Aussagen zu treffen oder ein ML-Modell zu trainieren.\n",
    "\n",
    "### Vervollständigung (Imputation) mit fillna()\n",
    "\n",
    "Auch bei den Angaben zur Farbe fehlen Einträge. Zum Beispiel die Zeile mit\n",
    "dem Index 2 ist unvollständig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch.loc[2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049a3fb",
   "metadata": {},
   "source": [
    "Diesmal entscheiden wir uns dazu, diese Eigenschaft nicht wegzulassen.\n",
    "ML-Verfahren brauchen aber immer einen gültigen Wert und nicht `NaN`. Wir müssen\n",
    "daher den fehlenden Wert ersetzen. Eine Möglichkeit ist, eine Farbe zu erfinden,\n",
    "z.B. 'bunt', oder die fehlenden Werte explizit durch einen Eintrag 'keine\n",
    "Angabe' zu vervollständigen. Dazu benutzen wir die Methode `fillna()` (siehe\n",
    "[Pandas-Dokumentation →\n",
    "fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)).\n",
    "Die Vervollständigung soll nur die NaN-Werte der Spalte »Farbe« füllen. Daher\n",
    "filtern wir zuerst diese Spalte und wenden darauf die `fillna()`-Methode an. Das\n",
    "erste Argument der `fillna()`-Methode ist der Wert, durch den die NaN-Werte\n",
    "ersetzt werden sollen (hier `'keine Angabe'`). Damit die Verwollständigung\n",
    "explizit gespeichert wird, überschreiben wir die Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch['Farbe'] = daten_ohne_verbrauch['Farbe'].fillna('keine Angabe')\n",
    "\n",
    "# Kontrolle der Vervollständigung\n",
    "daten_ohne_verbrauch.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98f31e",
   "metadata": {},
   "source": [
    "Wenn wir uns jetzt noch einmal die dritte Zeile ansehen, sehen wir, dass\n",
    "`fillna()` funktioniert hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch.loc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a773c1b",
   "metadata": {},
   "source": [
    "Bei den PS-Zahlen haben wir ebenfalls nicht vollständige Daten vorliegen.\n",
    "Diesmal haben wir nicht kategoriale Daten wie die Farben, sondern numerische\n",
    "Werte. Daher bietet es sich hier eine zweite Methode der Ersetzung (Imputation)\n",
    "an. Wenn wir überall da, wo keine PS-Zahlen vorliegen, den Mittelwert der\n",
    "vorhandenen PS-Zahlen einsetzen, machen wir zumindest den Mittelwert des\n",
    "gesamten Datensatzes nicht kaputt. Wir berechnen daher zuerst den Mittelwert mit\n",
    "der Methode `.mean()` und nutzen dann die `fillna()`-Methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1298a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mittelwert = daten_ohne_verbrauch['Leistung (PS)'].mean()\n",
    "print(f'Der Mittelwert der vorhandenen Einträge »Leistung (PS)« ist: {mittelwert:.2f}')\n",
    "\n",
    "daten_ohne_verbrauch['Leistung (PS)'] = daten_ohne_verbrauch['Leistung (PS)'].fillna(mittelwert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4839889",
   "metadata": {},
   "source": [
    "Noch einmal die Kontrolle, ob jetzt alle NaN-Werte eliminiert oder\n",
    "vervollständigt wurden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_ohne_verbrauch.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9856ba",
   "metadata": {},
   "source": [
    "Der Mittelwert der »Leistung (PS)« ist sehr hoch. Vielleicht haben wir doch den\n",
    "Datensatz eher verschlechtert, indem wir fehlende Werte durch den Mittelwert\n",
    "ersetzt haben. Beispielsweise könnte der Median eine bessere Alternative sein.\n",
    "Auch könnten wir zunächst die Autos mit fehlenden PS-Zahlen weglassen, für die\n",
    "übrigen Autos ein lineares Regressionsmodell oder einen Entscheidungsbaum\n",
    "trainieren und damit die fehlenden PS-Zahlen abschätzen. Bei diesem Beispiel\n",
    "wäre die beste Lösung zur Imputation der ungültigen Werte »Leistung (PS)« die\n",
    "Umrechung der vorhandenen, gültigen Werte der Spalte »Leistung (kW)«.\n",
    "Tatsächlich sind die beiden Merkmale redundant, da es sich um dasselbe Merkmal\n",
    "in zwei verschiedenen Einheiten handelt, so dass wir die Spalte »Leistung (PS)«\n",
    "auch entfernen könnten.\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 8.1\n",
    "\n",
    "Ein wichtiger Teil eines ML-Projektes beschäftigt sich mit der Aufbereitung der\n",
    "Daten für die ML-Algorithmen. Dabei ist es nicht nur wichtig, in großen\n",
    "Datensammlungen fehlende Einträge aufspüren zu können, sondern ein Gespür dafür\n",
    "zu entwickeln, wie mit den fehlenden Daten umgegangen werden soll. Die\n",
    "Strategien hängen dabei von der Anzahl der fehlenden Daten und ihrer Bedeutung\n",
    "ab. Häufig werden unvollständige Daten aus der Datensammlung gelöscht\n",
    "(Elimination) oder numerische Einträge durch den Mittelwert der vorhandenen\n",
    "Daten ersetzt (Imputation). Wie kategoriale Daten für ML-Algorithmen aufbereitet\n",
    "werden müssen, wird im nächsten Kapitel erklärt.\n",
    "\n",
    "## 8.2 Trainings- und Testdaten\n",
    "\n",
    "Bei den Entscheidungsbäumen und der linearen Regression haben wir mit der\n",
    "`score()`-Methode bewertet, wie viele der Daten durch das Modell korrekt\n",
    "prognostiziert wurden. Je näher der Score an 1 liegt, desto besser. Doch selbst\n",
    "ein perfekter Score bedeutet nicht zwangsläufig, dass das Modell optimal ist. Es\n",
    "könnte überangepasst (overfitted) sein und daher bei neuen, unbekannten Daten\n",
    "schlechte Prognosen liefern. Im Folgenden beschäftigen wir uns mit der\n",
    "Aufteilung von Daten in Trainings- und Testdaten.\n",
    "\n",
    "### Lernziele Kapitel 8.2\n",
    "\n",
    "* Sie verstehen, warum Daten in **Trainingsdaten** und **Testdaten** aufgeteilt\n",
    "  werden.\n",
    "* Sie können mit der Funktion **train_test_split()** Pandas-DataFrames in\n",
    "  Trainings- und Testdaten aufteilen.\n",
    "* Sie kennen das Konzept der **Kreuzvalidierung**.\n",
    "\n",
    "### Auswendiglernen nützt nichts\n",
    "\n",
    "Um die Herausforderungen bei der Modellauswahl zu verdeutlichen, betrachten wir\n",
    "einen künstlich generierten Datensatz. Angenommen, wir hätten die folgenden 20\n",
    "Messwerte erfasst und möchten ein Regressionsproblem lösen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ca734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "\n",
    "# Generierung Daten\n",
    "daten = pd.DataFrame()\n",
    "daten['Ursache'] = [1.8681193560547067, 0.18892899670288932, 1.8907374398595373, 0.8592639746974586, 0.7909152983890833, -1.1356420176784945, 1.905097819104967, -1.9750789791816405, -0.9880705504662242, -0.26083387038221684, 1.1175316871750098, -1.2092597015989877, 1.451972942396889, 1.933602708701251, -1.3446310343812051, 0.38933577573143685, -1.96405560932978, -0.45371486942548245, -1.8233597682740017, 1.8266118708569437]\n",
    "daten['Wirkung'] = [18.06801933135814, 0.09048390063552635, 18.29951272892001, 4.02392603643671, 1.97091878521032, 6.799411114666941, 17.540101218695103, 21.051664199041685, 5.604758672240995, 0.38630710692300024, 5.261393705782588, 7.365977868421521, 10.701020062336028, 17.48514901635516, 11.263523310016517, 1.1522069460363902, 20.979929897937023, -0.08352624016486021, 18.258951764602635, 15.321589041941028]\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', title= 'Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db94793",
   "metadata": {},
   "source": [
    "Nun würden wir das folgende Modell implementieren. Der Name des Modells sagt\n",
    "bereits alles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class AuswendigLerner:\n",
    "    def __init__(self) -> None:\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f2106",
   "metadata": {},
   "source": [
    "Wir trainieren unser Modell und lassen es dann bewerten. Um nicht selbst den\n",
    "R²-Score implementieren zu müssen, verwenden wir die allgemeine Funktion aus\n",
    "Scikit-Learn (siehe [Dokumentation Scikit-Learn →\n",
    "r2_score()}(https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaption der Daten\n",
    "X = daten[['Ursache']]\n",
    "y = daten['Wirkung']\n",
    "\n",
    "# Auswahl Modell und Training\n",
    "mein_super_modell = AuswendigLerner()\n",
    "mein_super_modell.fit(X, y)\n",
    "\n",
    "# prediction\n",
    "y_prognose = mein_super_modell.predict(X)\n",
    "\n",
    "# check quality\n",
    "score = r2_score(y,y_prognose)\n",
    "print(f'Der R2-Score ist: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c87fcd",
   "metadata": {},
   "source": [
    "Ein R²-Score von 1, unser Modell scheint perfekt zu funktionieren! Doch wie\n",
    "prognostiziert es neue Daten? Das Modell funktioniert zwar hervorragend für die\n",
    "gegebenen Trainingsdaten, ist jedoch **nicht verallgemeinerbar**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mein_super_modell.predict([[1.3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307a6c1",
   "metadata": {},
   "source": [
    "Anstatt für den x-Wert $1.3$ (Ursache) eine Prognose zu treffen, gibt das Modell\n",
    "einfach die auswendig gelernten y-Werte (Wirkungen) aus.\n",
    "\n",
    "### Daten für später aufheben\n",
    "\n",
    "Bei der Modellauswahl und dem Training des Modells müssen wir zusätzlich\n",
    "sicherstellen, dass das Modell verallgemeinerbar ist, das heißt, dass es auch\n",
    "für neue, zukünftige Daten verlässliche Prognosen liefern kann. Da wir jedoch\n",
    "sofort abschätzen wollen, wie gut das Modell auf neue Daten reagiert, und nicht\n",
    "warten möchten, bis die nächsten Messungen vorliegen, legen wir jetzt schon\n",
    "einen Teil der vorhandenen Daten zur Seite. Diese Daten nennen wir\n",
    "**Testdaten**. Die verbleibenden Daten verwenden wir für das Training des\n",
    "Modells ﹣ sie heißen **Trainingsdaten**. Später nutzen wir die Testdaten, um zu\n",
    "überprüfen, wie gut das Modell bei Daten funktioniert, die nicht zum Training\n",
    "verwendet wurden.\n",
    "\n",
    "Für die Aufteilung in Trainings- und Testdaten verwenden wir eine dafür\n",
    "vorgesehene Funktion von Scikit-Learn namens `train_test_split()` (siehe\n",
    "[Dokumentation Scikit-Learn →\n",
    "train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n",
    "Diese Funktion müssen wir aus dem Modul `sklearn.model_selection` importieren.\n",
    "Dann übergeben wir `train_test_split()` die Daten, die aufgeteilt werden sollen,\n",
    "und erhalten als Rückgabe zwei DataFrames: Der erste enthält die Trainingsdaten,\n",
    "der zweite die Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbe25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "daten_train, daten_test = train_test_split(daten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1609459",
   "metadata": {},
   "source": [
    "Nun wollen wir sehen, welche Datenpunkte zu den Trainingsdaten und welche zu den\n",
    "Testdaten gehören. Dazu fügen wir dem Datensatz ein neues Merkmal hinzu und\n",
    "füllen es mit den Strings `'Trainingsdaten'` bzw. `'Testdaten'`. Anschließend\n",
    "visualisieren wir die Datenpunkte wie oben, wobei die Punkte entsprechend ihrer\n",
    "Zugehörigkeit (Trainings- oder Testdaten) eingefärbt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anreicherung der Daten mit dem Splitstatus\n",
    "daten.loc[daten_train.index,'Splitstatus'] = 'Traingsdaten'\n",
    "daten.loc[daten_test.index, 'Splitstatus'] = 'Testdaten'\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', color='Splitstatus', \n",
    "title='Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98350895",
   "metadata": {},
   "source": [
    "Standardmäßig hält die Funktion `train_test_split()` 25 % der Daten als\n",
    "Testdaten zurück. Ein schnelles Zählen der fünf Testdatenpunkte bestätigt dies.\n",
    "Die Auswahl der Testdaten erfolgt zufällig, sodass jeder Durchlauf des Codes\n",
    "eine andere Aufteilung der Daten erzeugt.\n",
    "\n",
    "Die Funktion bietet aber auch Optionen, um die Aufteilung nach eigenen Wünschen\n",
    "anzupassen:\n",
    "\n",
    "* `test_size`: Mit der Option `test_size` kann ein anderer Anteil als 25 % für\n",
    "  die Testdaten festgelegt werden. Möchte man zum Beispiel nur 10 % der Daten\n",
    "  als Testdaten zurückhalten, kann man `test_size=0.1` einstellen. Der Anteil\n",
    "  wird als Float zwischen 0.0 und 1.0 angegeben. Verwendet man stattdessen einen\n",
    "  Integer, interpretiert Scikit-Learn diesen als Anzahl der Testdatenpunkte.\n",
    "  `test_size=7` bedeutet also, dass sieben Datenpunkte als Testdaten verwendet\n",
    "  werden.\n",
    "* `random_state`: Die zufällige Auswahl der Testdaten erfolgt durch einen\n",
    "  Zufallszahlengenerator, der bei jedem Durchlauf neu gestartet wird. Wenn wir\n",
    "  zwar eine zufällige Auswahl wollen, aber den Neustart des\n",
    "  Zufallszahlengenerators verhindern möchten, können wir den Ausgangszustand des\n",
    "  Generators mit einem festen Wert (Integer) festlegen. Das ist vor allem für\n",
    "  Präsentationen oder Lehrmaterialien nützlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97597d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten_train, daten_test = train_test_split(daten, test_size=7, random_state=0)\n",
    "\n",
    "# Aktualisierung des Splitstatus\n",
    "daten.loc[daten_train.index,'Splitstatus'] = 'Traingsdaten'\n",
    "daten.loc[daten_test.index, 'Splitstatus'] = 'Testdaten'\n",
    "\n",
    "# Visualisierung\n",
    "fig = px.scatter(daten, x = 'Ursache', y = 'Wirkung', color='Splitstatus', \n",
    "title='Künstlich generierte Messdaten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2574e0",
   "metadata": {},
   "source": [
    "### Idee der Kreuzvalidierung\n",
    "\n",
    "Das Zurückhalten eines Teils der Daten als Testdaten hat den Nachteil, dass\n",
    "weniger Daten für das Training zur Verfügung stehen. Besonders bei kleinen\n",
    "Datensätzen kann dies dazu führen, dass das Modell ungenau oder schlecht\n",
    "trainiert wird. Hier kommt die Kreuzvalidierung ins Spiel.\n",
    "\n",
    "Die Idee der **Kreuzvalidierung** ist, die Daten in mehrere Teilmengen zu\n",
    "unterteilen und das Modell mehrmals zu trainieren und zu testen, um die Leistung\n",
    "besser beurteilen zu können. Schauen wir uns zunächst die zweifache\n",
    "Kreuzvalidierung an:\n",
    "\n",
    "Bei der zweifachen Kreuzvalidierung teilen wir die Daten in zwei Teilmengen, A\n",
    "und B. Das Modell wird dann zweimal trainiert und getestet: einmal mit A als\n",
    "Trainingsdaten und B als Testdaten, und einmal umgekehrt. Die endgültige\n",
    "Modellbewertung ergibt sich aus dem Durchschnitt der beiden Testergebnisse.\n",
    "\n",
    "Die dreifache Kreuzvalidierung funktioniert ähnlich, mit dem Unterschied, dass\n",
    "die Daten in drei Teilmengen A, B und C aufgeteilt werden. In drei Durchläufen\n",
    "wird jeweils mit zwei der Teilmengen trainiert und mit der dritten getestet:\n",
    "\n",
    "* Im ersten Durchlauf wird mit A und B trainiert und mit C getestet.\n",
    "* Im zweiten Durchlauf wird mit B und C trainiert und mit A getestet.\n",
    "* Im dritten Durchlauf wird mit A und C trainiert und mit B getestet. Am Ende\n",
    "wird der Durchschnitt der drei Testergebnisse als Maß für die Modellleistung\n",
    "verwendet.\n",
    "\n",
    "Dieses Verfahren lässt sich auf beliebig viele Teilmengen erweitern.\n",
    "Scikit-Learn bietet dafür auch spezielle Funktionen zur effizienten Umsetzung\n",
    "der Kreuzvalidierung. Eine detailliertere Betrachtung dieser Techniken erfolgt\n",
    "jedoch in einem späteren Kapitel. An dieser Stelle soll lediglich das Konzept\n",
    "der Kreuzvalidierung eingeführt werden.\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 8.2\n",
    "\n",
    "In diesem Abschnitt haben wir die Aufteilung von Daten in Trainings- und\n",
    "Testdaten kennengelernt und die Funktion `train_test_split()` verwendet. Diese\n",
    "Funktion wird uns in zukünftigen Kapiteln und Projekten begleiten. Zudem haben\n",
    "wir eine erste Einführung in die Kreuzvalidierung erhalten, die wir später\n",
    "ausführlicher behandeln werden.\n",
    "\n",
    "## 8.3 Kodierung und Skalierung\n",
    "\n",
    "ML-Algorithmen können nur Zahlen verarbeiten. In diesem Kapitel werden wir uns\n",
    "zunächst damit beschäftigen, wie auch kategoriale Daten wie beispielsweise die\n",
    "Farbe eines Autos verarbeitet werden können. Da viele ML-Modelle empfindlich\n",
    "darauf reagieren, wenn die numerischen Werte in sehr unterschiedlichen\n",
    "Größenordnungen liegen, beschäftigen wiruns auch mit der Sklaierung von\n",
    "numerischen Daten.\n",
    "\n",
    "### Lernziele Kapitel 8.3\n",
    "\n",
    "* Sie können geordnete kategoriale (= ordinale) Daten mit Hilfe eines\n",
    "  Dictionaries und der `replace()`-Methode als Zahlen kodieren.\n",
    "* Sie können ungeordnete kategoriale (= nominame) Daten mit Hilfe der\n",
    "  `get_dummies()`-Methode als Zahlen kodieren. Diese Methode nennt man\n",
    "  **One-Hot-Kodierung**.\n",
    "* Sie können numerische Daten skalieren, indem Sie\n",
    "  * mit dem **MinMaxScaler** die Daten **normieren** oder\n",
    "  * mit dem **StandardScaler** die Daten **standardisieren**.\n",
    "\n",
    "### Kodierung von kategorialen Daten\n",
    "\n",
    "Bei den Beispielen zur linearen Regression haben wir zur Prognose des\n",
    "Verkaufspreises nur numerische Daten genutzt, wie beispielsweise den\n",
    "Kilometerstand. Es gibt jedoch weitere Merkmale, die die Kaufentscheidung\n",
    "beeinflussen, wie der Kraftstofftyp (Diesel oder Benzin) und die Marke des\n",
    "Autos. Diese würden wir ebenfalls gerne in die Prognose des Preises einfließen\n",
    "lassen. Dazu müssen die kategorialen Daten, die in der Regel durch den Datentyp\n",
    "String gekennzeichnet sind, vorab in Integers oder Floats umgewandelt werden. Je\n",
    "nachdem, ob die kategorialen Daten geordnet oder ungeordnet sind, gibt es\n",
    "verschiedene Vorgehensweisen, wie wir uns im Folgenden anhand eines Beispiels\n",
    "erarbeiten.\n",
    "\n",
    "Wir laden einen Datensatz mit Verkaufsdaten der Plattform\n",
    "[Autoscout24.de](https://www.autoscout24.de). Sie können die csv-Datei hier\n",
    "herunterladen:\n",
    "<https://gramschs.github.io/book_ml4ing/data/autoscout24_kodierung.csv> und in\n",
    "das Jupyter Notebook importieren. Alternativ können Sie die csv-Datei auch über\n",
    "die URL importieren, wie es in der folgenden Code-Zelle gemacht wird. Mit der\n",
    "Methode `.info()`lassen wir uns anzeigen, welchen Datentyp die Merkmale haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url = 'https://gramschs.github.io/book_ml4ing/data/autoscout24_kodierung.csv'\n",
    "daten = pd.read_csv(url)\n",
    "\n",
    "daten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361f1dc",
   "metadata": {},
   "source": [
    "Wir sehen\n",
    "\n",
    "* 8 Merkmale mit Datentyp `object`: Marke, Modell, Farbe, Erstzulassung,\n",
    "  Getriebe, Kraftstoff, Bemerkungen, Zustand,\n",
    "* 4 Merkmale mit Datentyp `int64`: Jahr, Preis (Euro), Leistung (PS), Leistung\n",
    "  (kW)\n",
    "* 2 Merkmale mit Datentyp `float64`: Verbrauch (l/100 km) und Kilometerstand\n",
    "  (km).\n",
    "\n",
    "Als erstes betrachten wir geordnete Daten.\n",
    "\n",
    "#### Geordnete kategoriale Daten mit zwei Kategorien (binär ordinale Daten)\n",
    "\n",
    "Als erstes betrachten wir das Merkmal »Getriebe«. Mit der Methode `.unique()`\n",
    "ermitteln wir, wie viele verschiedene Kategorien es für dieses Merkmal gibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca55222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten['Getriebe'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6ccab",
   "metadata": {},
   "source": [
    "Es gibt nur zwei Kategorien: Automatik und Schaltgetriebe. Diese beiden Werte\n",
    "wollen wir durch Integers ersetzen:\n",
    "\n",
    "* Automatik --> 0 und\n",
    "* Schaltgetriebe --> 1.\n",
    "\n",
    "Pandas bietet dazu die Methode `replace()` an. Bei der Verwendung dieser Methode\n",
    "darf sich der Datentyp nicht ändern (in Pandas Version 2 noch erlaubt, ab\n",
    "Version 3 verboten). Daher kodieren wir zunächst die Strings `'Automatik'` und\n",
    "`'Schaltgetriebe'` als die Strings `'0'` und `'1'`mit Hilfe eines Dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "getriebe_kodierung = {\n",
    "  'Automatik': '0',\n",
    "  'Schaltgetriebe': '1',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb5ee5",
   "metadata": {},
   "source": [
    "Dann verwenden wir `replace()`, um die Ersetzung vorzunehmen. Zuletzt wandeln\n",
    "wir die Strings `'0'` und `'1'` noch mit der Methode `astype()` in Integers um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten['Getriebe'] = daten['Getriebe'].replace(getriebe_kodierung)\n",
    "daten['Getriebe'] = daten['Getriebe'].astype('int')\n",
    "\n",
    "# Kontrolle\n",
    "daten['Getriebe'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b82375",
   "metadata": {},
   "source": [
    "#### Geordnete kategoriale Daten (ordinale Daten)\n",
    "\n",
    "Für das Merkmal »Zustand« gibt es vier Kategorien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten['Zustand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8b4df",
   "metadata": {},
   "source": [
    "Die vier Zustände haben eine Ordnung, denn ein Neuwagen ist wertvoller als ein\n",
    "Jahreswagen. Der Jahreswagen wiederum ist im Allgmeinen wertvoller als der junge\n",
    "Gebrauchtwagen. Am wenigsten wertvoll ist der Gebrauchtwagen. Durch diese\n",
    "Ordnung ist es sinnvoll, beim Kodieren der Zustände durch Integers die Ordnung\n",
    "beizubehalten. Ob wir jetzt die 0 für den Neuwagen vergeben und die 3 für den\n",
    "Gebrauchtwagen oder umgekehrt, ist Geschmackssache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zustand_kodierung = {\n",
    "  'Gebrauchtwagen': '0',\n",
    "  'junger Gebrauchtwagen': '1', \n",
    "  'Jahreswagen': '2',\n",
    "  'Neuwagen': '3'\n",
    "}\n",
    "\n",
    "daten['Zustand'] = daten['Zustand'].replace(zustand_kodierung)\n",
    "daten['Zustand'] = daten['Zustand'].astype('int')\n",
    "\n",
    "# Kontrolle\n",
    "daten['Zustand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9117685",
   "metadata": {},
   "source": [
    "#### Ungeordnete kategoriale Daten (nominale Daten): One-Hot-Kodierung\n",
    "\n",
    "Anders verhät es sich bei den ungeordnetem kategorialen Daten wie beispielsweise\n",
    "den Farben der Autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten['Farbe'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85875745",
   "metadata": {},
   "source": [
    "14 verschiedene Farben haben die Autos in dem Datensatz. Es wäre jedoch falsch,\n",
    "nun Integers von 0 bis 13 zu vergeben, denn das würde eine Ordnung der Farben\n",
    "voraussetzen, die es nicht gibt. Wir verwenden daher das Verfahren der\n",
    "**One-Hot-Kodierung**. Anstatt einer Spalte mir den Farben führen wir 14 neue\n",
    "Spalten mit den Farben 'grau', 'grün', 'schwarz', 'blau', usw. ein. Wenn ein\n",
    "Auto die Farbe 'grau' hat, notieren wir in der Spalte 'grau' in dieser Zeile\n",
    "eine 1 und in den übrigen 13 Spalten mit den anderen Farben eine 0. So können\n",
    "wir die Farben numerisch kodieren, ohne eine Ordnung der Farben einzuführen, die\n",
    "es nicht gibt. Pandas bietet dafür die Methode `get_dummies()`an. Schauen wir\n",
    "uns zunächst an, was diese Methode bewirkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a4f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(daten['Farbe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85415e72",
   "metadata": {},
   "source": [
    "Damit haben wir die Spalte »Farbe« nun durch 14 Spalten kodiert. Wir könnten nun\n",
    "im ursprünglichen Datensatz die Spalte »Farbe« löschen und die neuen 14 Spalten\n",
    "hinzufügen. Tatsächlich erledigt das Pandas bereits für uns, wenn wir die\n",
    "Methode etwas modifiziert aufrufen. Mit dem Argument `data=` übergeben wir nun\n",
    "den kompletten Datensatz und mit dem Argument `columns=` spezifizieren wir die\n",
    "Liste der ungeordneten kategorialen Daten, die One-Hot-kodiert werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff67bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten = pd.get_dummies(data=daten, columns=['Farbe'])\n",
    "daten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce78d97",
   "metadata": {},
   "source": [
    "Die neuen Spaltennamen sind eine Kombination aus dem alten Spaltennamen »Farbe«\n",
    "und den Kategorien.\n",
    "\n",
    "### Skalierung von numerischen Daten\n",
    "\n",
    "Nachdem wir uns intensiv mit den kategorialen Daten beschäftigt haben,\n",
    "betrachten wir nun die numerischen Daten. Wir laden den Original-Datensatz und\n",
    "entfernen die kategorialen Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gramschs.github.io/book_ml4ing/data/autoscout24_kodierung.csv'\n",
    "daten = pd.read_csv(url)\n",
    "\n",
    "daten = daten.drop(columns=['Marke', 'Modell', 'Farbe', 'Erstzulassung', \n",
    "                            'Getriebe', 'Kraftstoff','Bemerkungen', 'Zustand'])\n",
    "daten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474119b",
   "metadata": {},
   "source": [
    "Ein erster Blick auf die Daten zeigt bereits, dass die Eigenschaftswerte in\n",
    "unterschiedlichen Bereichen liegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ecbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832db1f4",
   "metadata": {},
   "source": [
    "Der Verbrauch gemessen in Litern pro 100 Kilometer liegt zwischen 5 und 10,\n",
    "wohingegen der Kilometerstand die 100000 km übersteigt.Das zeigt auch die\n",
    "Übersicht der statistischen Kennzahlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "daten.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcbd882",
   "metadata": {},
   "source": [
    "Damit ist auch der Boxplot nur noch schwer lesbar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "fig = px.box(daten)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7403bc",
   "metadata": {},
   "source": [
    "Das hat auch Auswirkungen auf das Training der ML-Modelle. Daher beschäftigen\n",
    "wir uns nun mit der Skalierung von Daten.\n",
    "\n",
    "Sind die Bereich der Daten von ihren Zahlenwerten sehr verschieden, sollten alle\n",
    "numerischen Werte in dieselbe Größenordnung gebracht werden. Dieser Vorgang\n",
    "heißt **Skalieren** der Daten. Gebräulich sind dabei zwei verschiedene Methoden:\n",
    "\n",
    "* **Normierung** und\n",
    "* **Standardisierung**.\n",
    "\n",
    "#### Normierung\n",
    "\n",
    "Bei der Normierung wird festgelegt, dass alle Zahlenwerte in einem festen\n",
    "Intervall liegen. Besonders häufig wird das Intervall $[0,1]$ genommen. Die\n",
    "Verbrauch (l/ 100 km), der zwischen 3.5 und 14.9 liegt, würde so transformiert\n",
    "werden, dass das Minimum 3.5 der 0 entspricht und das Maximum 14.9 der 1.\n",
    "Genauso würde mit den anderen Eigenschaften verfahren werden. Wir nutzen zur\n",
    "praktischen Umsetzung Scikit-Learn.\n",
    "\n",
    "Damit keine Informationen über die Testdaten in das Training des ML-Modells\n",
    "sickern (Data Leakage), wird die Normierung an das Minimum und das Maximum der\n",
    "Trainingsdaten angepasst und ggf. für die Testdaten angewendet. Damit können\n",
    "einzelne Testdaten auch außerhalb des Intervalls $[0,1]$ liegen. Wir splitten\n",
    "daher zunächst unsere Daten in Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "daten_train, daten_test = train_test_split(daten, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4558d",
   "metadata": {},
   "source": [
    "Dann importieren wir die Klasse `MinMaxScaler` aus dem Untermodul\n",
    "`sklearn.preprocessing` und erzeugen ein MinMaxScaler-Objekt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cebef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Auswahl Skalierungsmethode: Normierung\n",
    "normierung = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa495f",
   "metadata": {},
   "source": [
    "Jetzt wird das Minimum/Maximum jeder Spalte bestimmt, also der MinMaxScaler an\n",
    "die Trainingsdaten angepasst. Daher ist es nicht verwunderlich, dass die Methode\n",
    "`fit()` genannt wurde. Dem MinMaxScaler werden also die Trainingsdaten\n",
    "übergeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113fdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normierung.fit(daten_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0e821",
   "metadata": {},
   "source": [
    "Zuletzt erfolgt die Transformation der Daten mit der `transform()`-Methode. Dazu\n",
    "werden einmal die Trainingsdaten und einmal die Testdaten dem angepassten\n",
    "MinMaxScaler übergeben und die transformierten Daten in neuen Variablen\n",
    "gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation der Trainungs- und Testdaten\n",
    "X_train_normiert = normierung.transform(daten_train)\n",
    "X_test_normiert = normierung.transform(daten_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b4f26",
   "metadata": {},
   "source": [
    "Wir schauen in 'X_train_normiert' hinein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_normiert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ba5da",
   "metadata": {},
   "source": [
    "Die Normierung der Daten scheint funktioniert zu haben. Alle Werte liegen\n",
    "zwischen 0 und 1. Gleichzeitig haben wir aber die Pandas-DataFrame-Datenstruktur\n",
    "verloren. Die Normierung ist nicht für uns Menschen gedacht, sondern für den\n",
    "ML-Algorithmus. Daher nutzt Scikit-Learn die Transformation der Daten\n",
    "gleichzeitig für die Umwandlung in das speichereffizientere NumPy-Array, das für\n",
    "den ML-Algorithmus gebraucht wird.\n",
    "\n",
    "#### Standardisierung\n",
    "\n",
    "Oft sind Daten normalverteilt. Die Standardisierung berücksichtigt das und\n",
    "transformiert nicht auf ein festes Intervall, sondern verschiebt den Mittelwert\n",
    "auf 0 und die Varianz auf 1. Die normalverteilten Daten werden also\n",
    "standardnormalverteilt. Auch das lassen wir Scikit-Learn erledigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9fc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Auswahl Skalierungsmethode: Standardisierung\n",
    "standardisierung = StandardScaler()\n",
    "\n",
    "# Analyse: jede Spalte wird auf ihr Minimum und ihre Maximum hin untersucht\n",
    "# es werden immer die Trainingsdaten verwendet\n",
    "standardisierung.fit(daten_train)\n",
    "\n",
    "# Transformation der Trainungs- und Testdaten\n",
    "X_train_standardisiert = standardisierung.transform(daten_train)\n",
    "X_test_standardisiert = standardisierung.transform(daten_test)\n",
    "\n",
    "print(X_train_standardisiert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55a04f",
   "metadata": {},
   "source": [
    "Auch hier geht die Pandas-DataFrame-Struktur verloren.\n",
    "\n",
    "### Zusammenfassung und Ausblick\n",
    "\n",
    "Kategoriale Daten müssen kodiert werden, damit sind in einem ML-Algorithmus\n",
    "verarbeitet werden können. Geordnete kategoriale (ordinale) Daen können dabei\n",
    "über ein Dictionary und die `replace()`-Methode kodiert werden. Für ungeordnete\n",
    "kategoriale (nominale) Daten muss die One-Hot-Kodierung verwendet werden.\n",
    "\n",
    "Auch numerische Daten müssen häufig für ML-Algorithmen aufbereitet werden, vor\n",
    "allem, wenn die Daten in sehr unterschiedlichen Zahlenbereichen liegen. Bei den\n",
    "bisher eingeführten ML-Modellen lineare Regression und Entscheidungsbäumen ist\n",
    "die Skalierung der numerischen Daten nicht notwendig. Erst die nachfolgenden\n",
    "ML-Modelle werden davon Gebrauch machen."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
