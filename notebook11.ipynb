{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82c3769",
   "metadata": {},
   "source": [
    "# 11. ML-Workflow: Modellbewertung und Auswahl\n",
    "\n",
    "## 11.1 Kreuzvalidierung\n",
    "\n",
    "In der Praxis ist es entscheidend, dass ein ML-Modell nicht nur gute Prognosen\n",
    "für die Daten liefert, sondern auch für neue, unbekannte Daten zuverlässig\n",
    "funktioniert. Durch das Aufteilen der Daten in Trainings- und Testdaten können\n",
    "wir eine erste Einschätzung über die Verallgemeinerungsfähigkeit eines Modells\n",
    "treffen. Dieser Ansatz weist jedoch einige Schwächen auf, die wir in diesem\n",
    "Kapitel näher beleuchten. Im Anschluss lernen wir ein fortschrittlicheres\n",
    "Verfahren kennen: die Kreuzvalidierung, die über die einfache Aufteilung in\n",
    "Trainings- und Testdaten hinausgeht und eine robustere Bewertung der\n",
    "Modellleistung ermöglicht.\n",
    "\n",
    "### Lernziele Kapitel 11.1\n",
    "\n",
    "- Sie sind in der Lage, das Konzept der **Kreuzvalidierung (Cross Validation)**\n",
    "  verständlich zu erklären.\n",
    "- Sie können die Vor- und Nachteile der Kreuzvalidierung aufzählen und bewerten.\n",
    "- Sie können mit **KFold** einen Datensatz in verschiedene **Teilmengen\n",
    "  (Folds)** aufteilen.\n",
    "- Sie beherrschen die Durchführung einer Kreuzvalidierung mithilfe der Funktion\n",
    "  **cross_validate()**.\n",
    "\n",
    "### Idee der Kreuzvalidierung\n",
    "\n",
    "Ein zentraler Schritt im ML-Workflow ist die Aufteilung der Daten in einen\n",
    "Trainings- und einen Testdatensatz. Das Modell wird auf den Trainingsdaten\n",
    "trainiert und anschließend auf den Testdaten bewertet. Diese Methode hat jedoch\n",
    "auch Nachteile. Besonders bei kleinen Datensätzen ist es problematisch,\n",
    "beispielsweise 25 % der Daten für den Test zurückhalten zu müssen, da dies die\n",
    "Datenmenge für das Training reduziert. Zudem kann eine zufällige Aufteilung der\n",
    "Daten zu unbalancierten Splits führen, die die Trainings- und Testergebnisse\n",
    "verfälschen. Eine sinnvolle Alternative zu dieser simplen Aufteilung ist die\n",
    "**Kreuzvalidierung** (engl. **Cross Validation**).\n",
    "\n",
    "Bei der Kreuzvalidierung werden die Daten in mehrere **Teilmengen**, sogenannte\n",
    "**Folds**, aufgeteilt. Beispielsweise können die Daten in fünf Folds unterteilt\n",
    "werden. Das Modell wird dann fünfmal trainiert und getestet, wobei in jedem\n",
    "Durchlauf eine andere Teilmenge als Testdaten verwendet wird. Im ersten\n",
    "Durchlauf wird etwa Fold A für den Test zurückgehalten, während die Folds B, C,\n",
    "D und E zum Training genutzt werden. Im zweiten Durchlauf wird Fold B als\n",
    "Testdatensatz verwendet und die restlichen Folds dienen wieder dem Training.\n",
    "Dieser Prozess wird so lange wiederholt, bis jeder Fold einmal als Testdaten\n",
    "fungiert hat. Am Ende wird die Modellleistung (Score) als Durchschnitt der\n",
    "Ergebnisse aus den fünf Durchläufen berechnet.\n",
    "\n",
    "Es müssen jedoch nicht zwingend fünf Folds verwendet werden. Oftmals werden die\n",
    "Daten in zehn Folds aufgeteilt, sodass 90 % der Daten zum Training und 10 % für\n",
    "den Test verwendet werden. Ein weiterer Vorteil ist, dass jeder Datenpunkt im\n",
    "Laufe der Kreuzvalidierung sowohl im Training als auch im Test berücksichtigt\n",
    "wird, jedoch nie gleichzeitig. Dies verringert die Gefahr, dass unausgewogene\n",
    "Daten zu verzerrten Testergebnissen führen, wie es bei einer zufälligen\n",
    "Aufteilung passieren könnte.\n",
    "\n",
    "Zusammengefasst bietet die Kreuzvalidierung mehrere Vorteile:\n",
    "\n",
    "- **Effizientere Datennutzung**: Jeder Datenpunkt wird mindestens einmal als\n",
    "  Testdatenpunkt verwendet, was besonders bei kleinen Datensätzen wichtig ist,\n",
    "  da die Daten optimal ausgenutzt werden.\n",
    "- **Stabilere Schätzung der Modellleistung**: Durch das wiederholte Training und\n",
    "  Testen auf verschiedenen Daten erhöht sich die Robustheit der geschätzten\n",
    "  Modellleistung (Score), da zufällige Verzerrungen durch unbalancierte Splits\n",
    "  minimiert werden.\n",
    "\n",
    "Ein Nachteil der Kreuzvalidierung ist der erhöhte Rechenaufwand, da das Modell\n",
    "mehrfach trainiert und getestet wird.\n",
    "\n",
    "Können wir also auf die Aufteilung in Trainings- und Testdaten verzichten? Nein,\n",
    "denn für das Hyperparameter-Tuning ist der Split weiterhin notwendig. Mehr dazu\n",
    "im nächsten Kapitel. Zunächst widmen wir uns der praktischen Umsetzung der\n",
    "Kreuzvalidierung in Scikit-Learn.\n",
    "\n",
    "### Kreuzvalidierung mit KFold\n",
    "\n",
    "Um die Kreuzvalidierung in Scikit-Learn zu demonstrieren, generieren wir\n",
    "zunächst einen künstlichen Datensatz. Mithilfe der Funktion `make_moons()`\n",
    "erstellen wir 50 Datenpunkte und speichern sie in einem Pandas-DataFrame. Für\n",
    "eine einfachere Visualisierung mit Plotly Express wandeln wir die Zielvariable\n",
    "`'Wirkung'` von den Werten 0/1 in boolesche Werte (False/True) um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_moons \n",
    "\n",
    "X_array, y_array = make_moons(noise = 0.5, n_samples=50, random_state=3)\n",
    "daten = pd.DataFrame({\n",
    "    'Merkmal 1': X_array[:,0],\n",
    "    'Merkmal 2': X_array[:,1],\n",
    "    'Wirkung': y_array\n",
    "})\n",
    "daten['Wirkung'] = daten['Wirkung'].astype('bool')\n",
    "\n",
    "fig = px.scatter(daten, x = 'Merkmal 1', y = 'Merkmal 2', color='Wirkung',\n",
    "    title='Künstliche Daten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a0b0f",
   "metadata": {},
   "source": [
    "Als Nächstes laden wir die Klasse `KFold` aus dem Untermodul\n",
    "`sklearn.model_selection`. Wir instanziieren ein KFold-Objekt mit dem Argument\n",
    "`n_splits=5`, das die Daten in fünf Teilmengen (Folds) aufteilt. Tatsächlich ist\n",
    "dies die Standardeinstellung, wie uns die [Dokumentation Scikit-Learn →\n",
    "KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "zeigt. Das Argument könnte also weggelassen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fbb60",
   "metadata": {},
   "source": [
    "Im Hintergrund wurde ein Generator erzeugt, mit Hilfe dessen wir Daten in fünf\n",
    "Teilmengen (Folds) aufteilen können. Dazu benutzen wir die Methode `.split()`\n",
    "und übergeben ihr die Daten, die gesplittet werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8637a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold.split(daten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc131e",
   "metadata": {},
   "source": [
    "Zwar wurde hiermit die Aufteilung in fünf Teilmengen vollzogen, doch die\n",
    "eigentlichen Trainings- und Testdaten wurden noch nicht gespeichert und\n",
    "weiterverarbeitet. Mithilfe einer for-Schleife greifen wir in jedem Durchgang\n",
    "auf die Trainings- und Testindizes zu, die die Methode `split()` als Tupel\n",
    "zurückgibt. Das erste Element enthält die Indizes der Trainingsdaten, das zweite\n",
    "die der Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (train_index, test_index) in kfold.split(daten):\n",
    "  print(f'Index Trainingsdaten: {train_index}')\n",
    "  print(f'Index Testdaten: {test_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c9738b",
   "metadata": {},
   "source": [
    "Die Aufteilung der Daten erfolgt hierbei sehr systematisch. Im ersten Durchgang\n",
    "werden die Datenpunkte 0–9 als Testdaten verwendet, im zweiten Durchgang die\n",
    "Punkte 10–19 und so weiter. Bei sortierten Daten kann dies ungünstig sein. Um\n",
    "eine zufällige Aufteilung zu gewährleisten, können wir das Argument\n",
    "`shuffle=True` verwenden, um die Daten vor dem Split zu mischen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d11213",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in kfold.split(daten):\n",
    "  print(f'Index Trainingsdaten: {train_index}')\n",
    "  print(f'Index Testdaten: {test_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d9356",
   "metadata": {},
   "source": [
    "Nun verwenden wir diese fünf Aufteilungen, um einen Entscheidungsbaum zu\n",
    "trainieren. Dabei begrenzen wir die Baumtiefe auf 3 und bewerten in jedem\n",
    "Durchgang die Genauigkeit (Score) sowohl auf den Trainings- als auch auf den\n",
    "Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa00a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modell = DecisionTreeClassifier(max_depth=3) \n",
    "kfold = KFold(n_splits = 5, shuffle=True, random_state=0)\n",
    "\n",
    "for (train_index, test_index) in kfold.split(daten):\n",
    "  X_train = daten.loc[train_index, ['Merkmal 1', 'Merkmal 2']]\n",
    "  y_train = daten.loc[train_index, 'Wirkung']\n",
    "  X_test = daten.loc[test_index, ['Merkmal 1', 'Merkmal 2']]\n",
    "  y_test = daten.loc[test_index, 'Wirkung']\n",
    "  \n",
    "  modell.fit(X_train, y_train)\n",
    "  score_train = modell.score(X_train, y_train)\n",
    "  score_test = modell.score(X_test, y_test)\n",
    "\n",
    "  print(f'Score Training: {score_train:.2f}, Score Test: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aeb144",
   "metadata": {},
   "source": [
    "Die Scores auf den Trainingsdaten könnten den Eindruck erwecken, dass der\n",
    "Entscheidungsbaum sehr gut funktioniert. Doch die Testdaten zeigen Schwankungen\n",
    "zwischen 0.4 und 0.8. Hätten wir eine einfache Aufteilung in Trainings- und\n",
    "Testdaten vorgenommen und zufällig den dritten Split erwischt, hätten wir\n",
    "wahrscheinlich eine zu optimistische Einschätzung der Modellqualität getroffen.\n",
    "Aus didaktischen Gründen verwenden wir das Argument `random_state=0`, um die\n",
    "Ergebnisse mit dem Vorlesungsskript vergleichbar zu machen.\n",
    "\n",
    "### Automatische Kreuzvalidierung mit cross_validate\n",
    "\n",
    "Wie so oft bietet Scikit-Learn eine elegantere und einfachere Möglichkeit, die\n",
    "Kreuzvalidierung (Cross Validation) durchzuführen, ohne manuell eine for-Schleife programmieren zu\n",
    "müssen. Die Funktion `cross_validate()` übernimmt die Durchführung der\n",
    "Kreuzvalidierung automatisch. Wir importieren sie aus dem Untermodul\n",
    "`sklearn.model_selection` und teilen anschließend die Daten in Eingabedaten `X`\n",
    "und Zielgröße `y` auf.\n",
    "\n",
    "Die Funktion `cross_validate()` wird mit dem ML-Modell (hier einem\n",
    "Entscheidungsbaum), den Eingabedaten `X` und der Zielgröße `y` aufgerufen.\n",
    "Standardmäßig wird eine 5-fache Kreuzvalidierung ohne Mischen durchgeführt. Mit\n",
    "dem optionalen Argument `cv=` kann jedoch auch ein benutzerdefinierter\n",
    "Aufteilungsgenerator übergeben werden, wie zum Beispiel `KFold`. Das zusätzliche\n",
    "Argument `return_train_score=True` sorgt dafür, dass auch die Trainingsscores in\n",
    "jedem Durchlauf gespeichert werden. Der entsprechende Code sieht folgendermaßen\n",
    "aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a778dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = daten[['Merkmal 1', 'Merkmal 2']]\n",
    "y = daten['Wirkung']\n",
    "\n",
    "cv_results = cross_validate(modell, X,y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32989b46",
   "metadata": {},
   "source": [
    "Die Funktion `cross_validate()` gibt ein Dictionary zurück, das wie folgt\n",
    "aufgebaut ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b975a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43416d",
   "metadata": {},
   "source": [
    "In diesem Dictionary sind zunächst die Rechenzeiten für das Training\n",
    "(`'fit_time'`) und die Prognose (`'score_time'`) gespeichert. Danach folgen die\n",
    "Scores der Testdaten (`'test_score'`). Falls das Argument\n",
    "`return_train_score=True` gesetzt wurde, enthält das Dictionary auch die Scores\n",
    "der Trainingsdaten (`'train_score'`). Die Scores können wir wie folgt anzeigen\n",
    "lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results['test_score'])\n",
    "print(cv_results['train_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a872d2",
   "metadata": {},
   "source": [
    "Weitere Details zu der Funktion `cross_validate()` finden Sie in der\n",
    "[Dokumentation Scikit-Learn →\n",
    "cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html).\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 11.1\n",
    "\n",
    "Die Kreuzvalidierung ist ein wichtiges Werkzeug, insbesondere wenn es um die\n",
    "Feinjustierung der Hyperparameter geht, also das sogenannte\n",
    "Hyperparameter-Tuning. Im nächsten Kapitel werden wir uns mit der Kombination\n",
    "von Kreuzvalidierung (Cross Validation) und einer Gittersuche (Grid Search)\n",
    "beschäftigen, um die optimalen Hyperparameter für ein Modell zu finden.\n",
    "\n",
    "## 11.2 Gittersuche\n",
    "\n",
    "Die Kreuzvalidierung wird selten isoliert verwendet. Sie ist jedoch ein\n",
    "unverzichtbares Werkzeug, wenn es darum geht, die Hyperparameter eines Modells\n",
    "zu optimieren. In diesem Kapitel vertiefen wir daher zunächst das Verständnis\n",
    "der Kreuzvalidierung, bevor wir sie im Rahmen der Gittersuche anwenden.\n",
    "\n",
    "### Lernziele Kapitel 11.2\n",
    "\n",
    "- Sie verstehen, dass Daten für die Modellauswahl in Trainingsdaten,\n",
    "  **Validierungsdaten** und Testdaten unterteilt werden.\n",
    "- Sie sind in der Lage, Hyperparameter mittels Gittersuche und Kreuzvalidierung\n",
    "  mithilfe von **GridSearchCV** zu optimieren.\n",
    "\n",
    "### Kreuzvalidierung zur Modellauswahl\n",
    "\n",
    "Im letzten Kapitel haben wir die Kreuzvalidierung eingeführt. Ihr Ziel ist es,\n",
    "eine robustere Bewertung der Modellleistung zu ermöglichen. Besonders bei der\n",
    "Beurteilung und der verbesserung der Verallgemeinerungsfähigkeit eines Modells\n",
    "(Reduktion von Overfitting), ist die Kreuzvalidierung ein wertvolles Werkzeug.\n",
    "In diesem Abschnitt nutzen wir die Kreuzvalidierung, um zwischen zwei Modellen\n",
    "zu wählen.\n",
    "\n",
    "Aus didaktischen Gründen verwenden wir weiterhin künstliche Daten, die mit der\n",
    "Funktion `make_moons()` aus dem Modul `sklearn.datasets` erzeugt werden. Diese\n",
    "speichern wir in einem Pandas DataFrame und visualisieren sie anschließend mit\n",
    "Plotly Express."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9327333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_array, y_array = make_moons(noise = 0.5, n_samples=100, random_state=3)\n",
    "daten = pd.DataFrame({\n",
    "    'Merkmal 1': X_array[:,0],\n",
    "    'Merkmal 2': X_array[:,1],\n",
    "    'Wirkung': y_array\n",
    "})\n",
    "daten['Wirkung'] = daten['Wirkung'].astype('bool')\n",
    "\n",
    "fig = px.scatter(daten, x = 'Merkmal 1', y = 'Merkmal 2', color='Wirkung',\n",
    "    title='Künstliche Daten')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a487d",
   "metadata": {},
   "source": [
    "Als nächstes trainieren wir einen Entscheidungsbaum. Da Entscheidungsbäume\n",
    "häufig zur Überanpassung (Overfitting) neigen, entscheiden wir uns, die\n",
    "Baumtiefe zu begrenzen. Aber welche Baumtiefe ist optimal? Die Baumtiefe ist ein\n",
    "Hyperparameter, der vor dem Training des Modells festgelegt wird. Mithilfe der\n",
    "Kreuzvalidierung können wir untersuchen, wie sich die Baumtiefe auf die\n",
    "Modellqualität auswirkt. Wir testen die Baumtiefen 3, 4, 5 und 6 und geben die\n",
    "Scores auf den Testdaten aus, wobei wir uns mit einer for-Schleife die Arbeit\n",
    "erleichtern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a233438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Adaption der Daten\n",
    "X = daten[['Merkmal 1', 'Merkmal 2']]\n",
    "y = daten['Wirkung']\n",
    "\n",
    "# Vorbereitung der Kreuzvalidierung mit 10 Splits\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "# wiederholte Kreuzvalidierung für Baumtiefe 3, 4, 5 und 6\n",
    "for max_tiefe in [3, 4, 5, 6]:\n",
    "    modell = DecisionTreeClassifier(max_depth=max_tiefe)\n",
    "    cv_results = cross_validate(modell, X,y, cv=kfold)\n",
    "    test_scores = cv_results['test_score']\n",
    "    print(f'Testscores: {test_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4205825",
   "metadata": {},
   "source": [
    "Die Ausgabe von 10 Testscores ist jedoch unübersichtlich. Stattdessen berechnen\n",
    "wir besser den Mittelwert (Mean) und die Standardabweichung (Standard Deviation)\n",
    "der Scores. Dazu importieren wir `mean()` und `std()` aus dem NumPy-Modul und\n",
    "passen die `print()`-Anweisung entsprechend an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "\n",
    "for max_tiefe in [3, 4, 5, 6]:\n",
    "    modell = DecisionTreeClassifier(max_depth=max_tiefe)\n",
    "    cv_results = cross_validate(modell, X,y, cv=kfold)\n",
    "    test_scores = cv_results['test_score']\n",
    "    print(f'Mittelwert Testscores: {mean(test_scores):.2f}, Standardabweichung: {std(test_scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d033a23b",
   "metadata": {},
   "source": [
    "Das beste Ergebnis erzielen wir mit einem Entscheidungsbaum der Tiefe 3. Diesen\n",
    "könnten wir nun als finales Modell wählen.\n",
    "\n",
    "Es gibt jedoch ein Problem: Wir haben die Modellauswahl mit den Scores der\n",
    "Testdaten begründet, wodurch diese in das Modelltraining eingeflossen sind. Daher\n",
    "benötigen wir einen frischen Datensatz, um die Prognosequalität zu testen. Die\n",
    "Lösung dafür ist `train_test_split()`.\n",
    "\n",
    "Zuerst teilen wir die Daten in Trainings- und Testdaten. Dann verwenden wir die\n",
    "Kreuzvalidierung auf den Trainingsdaten, um die Hyperparameter zu bewerten. Die\n",
    "Kreuzvalidierung teilt die Trainingsdaten erneut in Trainings- und Testdaten\n",
    "auf.  Damit diese »internen« Testdaten nicht mit den richtigen Testdaten\n",
    "verwechselt werden, nennt man sie auch **Validierungsdaten**. Die Mittelwerte\n",
    "der Scores speichern wir in einem Dictionary, um später das beste Modell zu\n",
    "ermitteln. Schließlich trainieren wir das beste Modell auf allen Trainingsdaten\n",
    "und bewerten es mit den Testdaten.\n",
    "\n",
    "Das Hyperparameter-Tuning bzw. die Modellwahl mit Kreuzvalidierung funktioniert\n",
    "komplett also wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = daten[['Merkmal 1', 'Merkmal 2']]\n",
    "y = daten['Wirkung']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "mean_scores = {}\n",
    "for max_tiefe in [3, 4, 5, 6]:\n",
    "    modell = DecisionTreeClassifier(max_depth=max_tiefe)\n",
    "    cv_results_modell = cross_validate(modell, X_train, y_train, cv=kfold)\n",
    "    test_scores = cv_results_modell['test_score']\n",
    "    mean_scores[max_tiefe] = mean(test_scores)\n",
    "    print(f'Mittelwert Testscores: {mean(test_scores):.2f}, Standardabweichung: {std(test_scores):.2f}')\n",
    "\n",
    "# Ermitteln der besten Baumtiefe (argmax o.ä. wäre einfacher)\n",
    "tiefe = 3\n",
    "score = mean_scores[3]\n",
    "for t in [4,5,6]:\n",
    "    if mean_scores[t] > score:\n",
    "        tiefe = t\n",
    "        score = mean_scores[t]\n",
    "print(f'\\nWähle Baumtiefe {tiefe} mit dem besten Score {score:.2f}.')\n",
    "\n",
    "# Finale Modellauswahl, Training und Bewertung\n",
    "finales_modell = DecisionTreeClassifier(max_depth=tiefe)\n",
    "finales_modell.fit(X_train, y_train)\n",
    "finaler_score = finales_modell.score(X_test, y_test)\n",
    "print(f'Testscore finales Modell: {finaler_score:.2f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3e7bf",
   "metadata": {},
   "source": [
    "Um die Hyperparameter zu optimieren und das beste Modell zu finden, haben wir\n",
    "eine for-Schleife und manuelle Auswahl verwendet. Scikit-Learn bietet jedoch\n",
    "eine einfachere Lösung, die wir im nächsten Abschnitt behandeln: die Gittersuche\n",
    "mit Kreuzvalidierung **GridSearchCV**.\n",
    "\n",
    "### Gittersuche mit Kreuzvalidierung: GridSearchCV\n",
    "\n",
    "Die Gittersuche mit Kreuzvalidierung wird als **GridSearchCV** aus dem Modul\n",
    "`sklearn.model_selection` importiert. Zunächst legen wir fest, welche Parameter\n",
    "optimiert werden sollen und welche Werte dafür in Betracht kommen. Technisch\n",
    "benötigen wir dafür ein Dictionary, in dem die Schlüssel die Parameternamen und\n",
    "die Werte Listen der möglichen Einstellungen sind. In unserem Fall soll die\n",
    "Baumtiefe `'max_depth'` des Entscheidungsbaums justiert werden. Wie zuvor in der\n",
    "for-Schleife, untersuchen wir die Baumtiefen 3, 4, 5 und 6, die im folgenden\n",
    "Dictionary `parameter_gitter` definiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614885d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Festlegung des Suchraumes\n",
    "parameter_gitter = {'max_depth': [3, 4, 5, 6]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449309a9",
   "metadata": {},
   "source": [
    "Nun instanziieren wir ein neues `GridSearchCV`-Modell. Als erstes Argument\n",
    "übergeben wir das eigentliche Modell, hier also den Entscheidungsbaum, und als\n",
    "zweites das Dictionary mit den Hyperparametern. Das dritte Argument ist die\n",
    "Methode zur Kreuzvalidierung. Weitere Details können Sie der [Dokumentation\n",
    "Scikit-Learn →\n",
    "GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "entnehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiertes_modell = GridSearchCV(DecisionTreeClassifier(), param_grid=parameter_gitter, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5554d9",
   "metadata": {},
   "source": [
    "Mit der Methode `.fit()` wird die Gittersuche samt Kreuzvalidierung\n",
    "durchgeführt. Dabei werden systematisch alle Parameterkombinationen getestet,\n",
    "und das optimierte Modell wird abschließend erneut auf den gesamten\n",
    "Trainingsdaten trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiertes_modell.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec024f",
   "metadata": {},
   "source": [
    "Mit der Methode `.score()` können wir die Modellgüte sowohl auf den Trainings-\n",
    "als auch auf den Testdaten bewerten. Auch die Methode `.predict()` funktioniert\n",
    "wie gewohnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_score_train = optimiertes_modell.score(X_train, y_train)\n",
    "opt_score_test  = optimiertes_modell.score(X_test, y_test)\n",
    "\n",
    "print(f'optimierter Entscheidungsbaum Score Trainingsdaten: {opt_score_train:.2f}')\n",
    "print(f'optimierter Entscheidungsbaum Score Testdaten: {opt_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abfb58",
   "metadata": {},
   "source": [
    "Zusätzlich zu den Standardmethoden wie `.fit()`, `.predict()` und `.score()`\n",
    "können wir mit dem Attribut `best_params_` herausfinden, welche\n",
    "Hyperparameter-Kombination am besten abgeschnitten hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47769123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimiertes_modell.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c12cc8",
   "metadata": {},
   "source": [
    "In diesem Fall ergibt die Gittersuche, dass die optimale Baumtiefe 3 beträgt.\n",
    "\n",
    "Warum sprechen wir von einer **Gittersuche**? Normalerweise wollen wir nicht nur\n",
    "einen Hyperparameter optimieren, sondern mehrere gleichzeitig. Beispielsweise\n",
    "könnten wir neben der Baumtiefe auch die minimale Anzahl an Datenpunkten pro\n",
    "Blatt (`min_samples_leaf`) optimieren. Dies führt dazu, dass wir jede\n",
    "Kombination von `max_depth` mit jedem Wert von `min_samples_leaf` testen. So\n",
    "entsteht ein zweidimensionales Gitter, das die Gittersuche effizient durchläuft.\n",
    "Wir müssen lediglich das Dictionary entsprechend erweitern. In diesem Beispiel\n",
    "werden 4 Baumtiefen und 3 Werte für `min_samples_leaf` kombiniert, was zu\n",
    "insgesamt 4 x 3 = 12 Hyperparameter-Kombinationen führt. Da wir 10-fache\n",
    "Kreuzvalidierung verwenden, werden insgesamt 120 Modelle trainiert und bewertet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d55776",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_gitter = {\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "optimiertes_modell = GridSearchCV(DecisionTreeClassifier(), param_grid=parameter_gitter, cv=kfold)\n",
    "optimiertes_modell.fit(X_train, y_train)\n",
    "\n",
    "opt_score_train = optimiertes_modell.score(X_train, y_train)\n",
    "opt_score_test  = optimiertes_modell.score(X_test, y_test)\n",
    "\n",
    "print(f'optimierter Entscheidungsbaum Score Trainingsdaten: {opt_score_train:.2f}')\n",
    "print(f'optimierter Entscheidungsbaum Score Testdaten: {opt_score_test:.2f}')\n",
    "\n",
    "print(optimiertes_modell.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25ef3d",
   "metadata": {},
   "source": [
    "Auch wenn bei diesem einfachen Beispiel die Unterschiede zwischen den Modellen\n",
    "gering sind und die Vorteile der Gittersuche mit Kreuzvalidierung nicht sofort\n",
    "ersichtlich werden, ist diese Methode bei größeren Datensätzen und komplexeren\n",
    "Modellen ein sehr wertvolles Werkzeug zur Modelloptimierung, bei der alle\n",
    "möglichen Kombinationen von Hyperparametern systematisch getestet werden. Dies\n",
    "kann jedoch sehr *rechenintensiv* sein, besonders wenn der Suchraum groß ist\n",
    "oder komplexe Modelle verwendet werden. Daher unterstützt GridSearchCV die\n",
    "*Parallelisierung* der Berechnungen, indem es mehrere Kerne verwendet, um die\n",
    "Rechenzeit signifikant zu verkürzen, was besonders bei größeren Datensätzen von\n",
    "Vorteil ist.\n",
    "\n",
    "Eine Alternative zu GridSearchCV ist **RandomizedSearchCV**. Dieses Verfahren\n",
    "testet eine zufällige Auswahl von Parametern testet und spart so Zeit, während\n",
    "es dennoch gute Ergebnisse liefert. Mehr Details dazu finden Sie in der\n",
    "[Dokumentation Scikit-Learn →\n",
    "RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV).\n",
    "\n",
    "```{dropdown} Video \"GridSearchCV\" von Normalized Nerd\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TvB_3jVIHhg?si=s2jDNKOmqBEcJcAd\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "```\n",
    "\n",
    "### Zusammenfassung und Ausblick Kapitel 11.2\n",
    "\n",
    "In diesem Kapitel haben wir erstmals systematisch Hyperparameter optimiert und\n",
    "dabei die Gittersuche mit Kreuzvalidierung angewendet. Im nächsten Kapitel\n",
    "lernen wir ein weiteres Werkzeug kennen, das nicht nur verschiedene Modelle,\n",
    "sondern auch deren Hyperparameter optimiert und anschließend Modellvorschläge\n",
    "basierend auf den besten Einstellungen macht.\n",
    "\n",
    "## Übung\n",
    "\n",
    "Der Datensatz Pinguine stammt von\n",
    "[HuggingFace](https://huggingface.co/datasets/SIH/palmer-penguins). Der\n",
    "Datensatz umfasst Daten von Pinguinen, insbesondere die Merkmale\n",
    "\n",
    "- Art,\n",
    "- Insel,\n",
    "- Schnabellaenge und Schnabeltiefe in Millimetern\n",
    "- Flossenlaenge in Millimetern,\n",
    "- Koerpergewicht in Gramm,\n",
    "- Geschlecht und\n",
    "- Jahr der Geburt.\n",
    "\n",
    "Laden Sie den Datensatz und führen Sie eine explorative Datenanalyse durch.\n",
    "Legen Sie 10 % der Daten als Testdaten zurück. Trainieren Sie dann ML-Modelle\n",
    "ggf. mit Gittersuche und wählen Sie das beste Modell aus. Welchen Score erreicht\n",
    "Ihr Modell für die Testdaten?\n",
    "\n",
    "In der folgenden Code-Zelle finden Sie import-Statements, die Sie bei Bedarf\n",
    "auskommentieren können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf3c11",
   "metadata": {},
   "source": [
    "### Überblick über die Daten\n",
    "\n",
    "Welche Daten enthält der Datensatz? Wie viele Pinguine sind in der Tabelle\n",
    "enthalten? Wie viele Merkmale werden dort beschrieben? Sind die Daten\n",
    "vollständig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f6102",
   "metadata": {},
   "source": [
    "### Datentypen\n",
    "\n",
    "Welchen Datentyp haben die Merkmale? Welche Merkmale sind numerisch und welche sind kategorial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69970541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d6de3",
   "metadata": {},
   "source": [
    "### Fehlende Einträge\n",
    "\n",
    "In welcher Spalte fehlen am meisten Einträge? Filtern Sie den Datensatz nach den\n",
    "fehlenden Einträgen und geben Sie eine Liste mit den Indizes (Zeilennummern)\n",
    "aus, wo Einträge fehlen. Löschen Sie anschließend diese Zeilen aus dem\n",
    "Datensatz. Sind jetzt alle Einträge gültig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9252f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e826e9f",
   "metadata": {},
   "source": [
    "### Analyse numerische Daten\n",
    "\n",
    "Erstellen Sie eine Übersicht der statistischen Merkmale für die numerischen\n",
    "Daten. Visualisieren Sie anschließend die statistischen Merkmale mit Boxplots.\n",
    "Verwenden Sie ein Diagramm für die Merkmale, die in Millimetern gemessen werden\n",
    "und ein Diagramm für das Körpergewicht. Interpretieren Sie die statistischen\n",
    "Merkmale. Gibt es Ausreißer? Sind die Werte plausibel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59399a",
   "metadata": {},
   "source": [
    "### Analyse der kategorialen Werte\n",
    "\n",
    "Untersuchen Sie die kategorialen Daten. Sind es wirklich kategoriale Daten?\n",
    "Prüfen Sie für jedes kategoriale Merkmal die Einzigartigkeit der auftretenden\n",
    "Werte und erstellen Sie ein Balkendiagramm mit den Häufigkeiten.\n",
    "\n",
    "Kommen alle Pinguin-Arten auf allen Inseln vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad233fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a16022",
   "metadata": {},
   "source": [
    "### ML-Modell\n",
    "\n",
    "Im Folgenden soll die Art der Pinguine anhand der numerischen Merkmale\n",
    "Schnabellaenge_mm, Schnabeltiefe_mm, Flossenlaenge_mm und Koerpergewicht_g\n",
    "klassifiziert werden.\n",
    "\n",
    "Trainieren Sie nun drei ML-Modelle:\n",
    "\n",
    "- Entscheidungsbaum (Decision Tree),\n",
    "- Random Forests und\n",
    "- SVM.\n",
    "\n",
    "Führen Sie dazu vorab einen Split in Trainings- und Testdaten durch. Verwenden\n",
    "Sie Kreuzvalidierung und/oder Gittersuche, um die Hyperparameter zu justieren.\n",
    "Für welches Modell würden Sie sich entscheiden? Begründen Sie Ihre Wahl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0014c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
